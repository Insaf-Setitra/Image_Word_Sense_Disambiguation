{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676abfff",
   "metadata": {},
   "source": [
    "# classify using a simple classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1784c2",
   "metadata": {},
   "source": [
    "### prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cb30c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image.0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image.1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image.10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image.100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image.1000.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0     image.0.jpg\n",
       "1     image.1.jpg\n",
       "2    image.10.jpg\n",
       "3   image.100.jpg\n",
       "4  image.1000.jpg"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Import the libraries\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from pathlib import Path\n",
    "\n",
    "mycwd = os.path.dirname(os.getcwd())\n",
    "# flags\n",
    "language = \"english\"\n",
    "#language = \"persian\"\n",
    "#language = \"italian\"\n",
    "search_engine = \"qwant\"\n",
    "search_engines = [\"bing\", \"qwant\", \"ecosia\"]\n",
    "#search_engines = [\"qwant\", \"ecosia\"]\n",
    "\n",
    "# folders\n",
    "folder_images = os.path.join(mycwd, \"0-dataset\", \"test_images\")\n",
    "root_txt =  os.path.join(mycwd, \"0-dataset\", \"test.data.v1.1.gold\")\n",
    "#folder_search = os.path.join(mycwd, \"9-Insaf_scrapSearch\", \"scrape_\"+language, search_engine, \"query\")\n",
    "\n",
    "if language == \"english\":\n",
    "    file_gold = os.path.join(root_txt,\"en.test.gold.v1.1.txt\")\n",
    "    file_data = os.path.join(root_txt,\"en.test.data.v1.1.txt\")\n",
    "elif language == \"persian\":\n",
    "    file_gold = os.path.join(root_txt,\"fa.test.gold.txt\")\n",
    "    file_data = os.path.join(root_txt,\"fa.test.data.txt\")\n",
    "elif language == \"italian\":\n",
    "    file_gold = os.path.join(root_txt,\"it.test.gold.v1.1.txt\")\n",
    "    file_data = os.path.join(root_txt,\"it.test.data.v1.1.txt\") \n",
    "\n",
    "folder_features_all = os.path.join(mycwd, \"12-Insaf_compute_features\", \"features_all\")\n",
    "file_features = os.path.join(folder_features_all, \"features.csv\")\n",
    "file_names = os.path.join(folder_features_all, \"image_names.csv\")\n",
    "\n",
    "folder_scrapped_features = os.path.join(mycwd, \"12-Insaf_compute_features\", \"features\")\n",
    "    \n",
    "\n",
    "df_data = pd.read_csv(file_data, delimiter='\\t', header=None)\n",
    "df_data.head()\n",
    "\n",
    "df_gold = pd.read_csv(file_gold, delimiter='\\t', header=None)\n",
    "df_gold.head()\n",
    "\n",
    "df_image_features = pd.read_csv(file_features, delimiter=',')\n",
    "df_image_features.head()\n",
    "\n",
    "df_image_names = pd.read_csv(file_names, delimiter='\\t')\n",
    "df_image_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f6aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e80221",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_contexts = []\n",
    "for i in range (df_gold.shape[0]):\n",
    "    feature_path = os.path.join(folder_scrapped_features, language, search_engine+\"_\"+str(i)+\".csv\")    \n",
    "    if os.path.isfile(feature_path)== False:\n",
    "        missing_contexts.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586aa8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 21, 23, 38, 40, 45, 46, 292, 302]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0cf939",
   "metadata": {},
   "source": [
    "I have downloaded those images (from scrapping code), and computed their features (from feature computation code), now the classification phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d6bad",
   "metadata": {},
   "source": [
    "### Prepare the data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0218b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feat = np.zeros((d))\n",
    "df_features = pd.DataFrame()\n",
    "features_i = []\n",
    "for i in range (df_gold.shape[0]):\n",
    "    image_index = df_image_names[df_image_names[\"0\"]==df_data.iloc[i][2]].index.values\n",
    "    featureC = df_image_features.iloc[image_index]\n",
    "    df_features = df_features.append(featureC)\n",
    "    file_scrapped_features = os.path.join(folder_scrapped_features, language, search_engine +\n",
    "                                          \"_\" + str(i) + \".csv\") \n",
    "    featureDB = pd.read_csv(file_scrapped_features, delimiter=',')\n",
    "    df_features = df_features.append(featureDB)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a6155a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.033182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029360</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.011287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022849</td>\n",
       "      <td>0.033434</td>\n",
       "      <td>0.039055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.058644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040015</td>\n",
       "      <td>0.029034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>0.033544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23606 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "3800  0.000000  0.036849  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "0     0.000000  0.000000  0.000000  0.027117  0.000000  0.000000  0.000000   \n",
       "1     0.004738  0.000000  0.000000  0.000000  0.000000  0.022488  0.000000   \n",
       "2     0.002935  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.020835  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "45    0.000000  0.000000  0.000000  0.000000  0.000000  0.008387  0.000000   \n",
       "46    0.000000  0.022849  0.033434  0.039055  0.000000  0.000000  0.015561   \n",
       "47    0.004506  0.000000  0.000000  0.074131  0.000000  0.010620  0.000000   \n",
       "48    0.000000  0.045931  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "49    0.000000  0.024209  0.000000  0.000000  0.021166  0.000000  0.000000   \n",
       "\n",
       "             7         8         9  ...      4086      4087      4088  \\\n",
       "3800  0.071793  0.000000  0.033347  ...  0.062409  0.000000  0.002975   \n",
       "0     0.017534  0.000000  0.002820  ...  0.000000  0.000000  0.000000   \n",
       "1     0.033879  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  ...  0.016983  0.000000  0.000000   \n",
       "3     0.018372  0.000000  0.010210  ...  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "45    0.031690  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "46    0.000000  0.000000  0.000000  ...  0.009730  0.058644  0.000000   \n",
       "47    0.000000  0.000000  0.000000  ...  0.010077  0.000000  0.000000   \n",
       "48    0.000000  0.040015  0.029034  ...  0.000000  0.035883  0.033544   \n",
       "49    0.005132  0.000000  0.006144  ...  0.009309  0.021034  0.000000   \n",
       "\n",
       "          4089      4090      4091      4092      4093      4094      4095  \n",
       "3800  0.000000  0.026942  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "0     0.009144  0.007342  0.033182  0.000000  0.000000  0.000000  0.000000  \n",
       "1     0.005606  0.000000  0.001500  0.000000  0.000000  0.029360  0.000000  \n",
       "2     0.000000  0.002928  0.000000  0.000000  0.000000  0.014986  0.011287  \n",
       "3     0.031686  0.000000  0.000000  0.000000  0.000000  0.001867  0.000000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "45    0.030686  0.000000  0.004898  0.013936  0.000000  0.008109  0.000000  \n",
       "46    0.000000  0.000000  0.000000  0.037968  0.000000  0.000000  0.000000  \n",
       "47    0.000000  0.000000  0.000000  0.000000  0.011789  0.000000  0.000000  \n",
       "48    0.000000  0.008194  0.000000  0.000000  0.000000  0.000000  0.041933  \n",
       "49    0.000000  0.034770  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[23606 rows x 4096 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5c593f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feat = np.zeros((d))\n",
    "df_labels = pd.DataFrame()\n",
    "for i in range (df_gold.shape[0]):\n",
    "    file_scrapped_features = os.path.join(folder_scrapped_features, language, search_engine +\n",
    "                                          \"_\" + str(i) + \".csv\") \n",
    "    featureDB = pd.read_csv(file_scrapped_features, delimiter=',')\n",
    "    df_labels = df_labels.append(pd.DataFrame(np.zeros((featureDB.shape[0]+1))+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "795a4ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23606, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e56ca6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23606, 4096)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "65379cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df_features.to_numpy(copy=True)\n",
    "y = df_labels.to_numpy(copy=True)\n",
    "y = y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b26bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9c76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e32b8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "354b89b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 2361 points : 1927\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "% (X_test.shape[0], (y_test != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0760e7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11803, 4096)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "616b5559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11803,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1c520edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11803)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(y_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c5dc5124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11803, 139049056)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test.shape[0], (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4313bf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d83be416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\utils\\fixes.py:357: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=10)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=10)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9360a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "550b4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 2361 points : 342\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "% (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "034272c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f9fa6",
   "metadata": {},
   "source": [
    "### prepare the data of the contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c9d81f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\utils\\fixes.py:357: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss=\"modified_huber\", max_iter=30).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d6da31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feat = np.zeros((d))\n",
    "matches = np.zeros((df_data.shape[0], 10))\n",
    "for i in range (df_gold.shape[0]):\n",
    "    for j in range (2,df_data.shape[1]):\n",
    "        image_index = df_image_names[df_image_names[\"0\"]==df_data.iloc[i][j]].index.values\n",
    "        featureC = df_image_features.iloc[image_index]\n",
    "        matches[i,j-2]= clf.predict_proba(featureC.to_numpy(copy=True).reshape(1,-1))[0][i]\n",
    "        \"\"\"print(\"treating image \", j)\n",
    "        print(clf.predict_proba(featureC.to_numpy(copy=True).reshape(1,-1))[0][i])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d3c6e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "956f40e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.320607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344579</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143884</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.576725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.264642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021139</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.160732</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031706</td>\n",
       "      <td>0.029881</td>\n",
       "      <td>0.046240</td>\n",
       "      <td>0.045726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133713</td>\n",
       "      <td>0.080122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.320252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.378705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.120816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342310</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.320607  0.000000  0.000000  0.000000  0.000000  0.138290  0.000000   \n",
       "1    0.510752  0.000000  0.000000  0.000000  0.000000  0.007056  0.000000   \n",
       "2    0.491299  0.000000  0.000000  0.000000  0.000000  0.012264  0.000000   \n",
       "3    0.340744  0.000000  0.000000  0.000000  0.000000  0.000000  0.143884   \n",
       "4    0.576725  0.000000  0.025201  0.000000  0.000000  0.000000  0.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "458  0.264642  0.000000  0.021139  0.012612  0.000000  0.000000  0.000000   \n",
       "459  0.160732  0.036255  0.000000  0.031706  0.029881  0.046240  0.045726   \n",
       "460  0.320252  0.000000  0.000000  0.645974  0.000000  0.000000  0.000000   \n",
       "461  0.378705  0.000000  0.000000  0.158792  0.000000  0.000000  0.180017   \n",
       "462  0.120816  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.000000  0.344579  0.000000  \n",
       "1    0.000000  0.000000  0.000000  \n",
       "2    0.000000  0.000000  0.000000  \n",
       "3    0.010515  0.000000  0.000000  \n",
       "4    0.000000  0.000000  0.000000  \n",
       "..        ...       ...       ...  \n",
       "458  0.000000  0.000000  0.000000  \n",
       "459  0.000000  0.133713  0.080122  \n",
       "460  0.000000  0.000000  0.000000  \n",
       "461  0.035107  0.000000  0.180447  \n",
       "462  0.000000  0.342310  0.000000  \n",
       "\n",
       "[463 rows x 10 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3448abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_images = []\n",
    "final_result_distances = []\n",
    "for idx, row in matches_df.iterrows():\n",
    "    dist_test = row\n",
    "    ranked_dist = -np.sort(-dist_test)\n",
    "    ranked_dist_indices = np.argsort(-dist_test)\n",
    "    sorted_df = np.array(df_data.iloc[idx][ranked_dist_indices+2])\n",
    "    final_result_images.append(sorted_df)\n",
    "    final_result_distances.append(ranked_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f6083878",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tocsv = pd.DataFrame()\n",
    "result_tocsv[\"language\"]=[]\n",
    "result_tocsv[\"data\"]=[]\n",
    "result_tocsv[\"candidate\"]=final_result_images\n",
    "result_tocsv[\"relevance\"]=final_result_distances\n",
    "result_tocsv[\"language\"]=language\n",
    "result_tocsv[\"gold\"]=df_gold.values\n",
    "result_tocsv[\"data\"]=range(len(final_result_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "62453ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>data</th>\n",
       "      <th>candidate</th>\n",
       "      <th>relevance</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>0</td>\n",
       "      <td>[image.2166.jpg, image.4418.jpg, image.4415.jp...</td>\n",
       "      <td>[0.34457918364900364, 0.32060663573968956, 0.1...</td>\n",
       "      <td>image.2166.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>[image.4429.png, image.4427.jpg, image.4422.jp...</td>\n",
       "      <td>[0.5107523260388563, 0.007055607515222442, 0.0...</td>\n",
       "      <td>image.4429.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>2</td>\n",
       "      <td>[image.4435.jpg, image.4432.jpg, image.4436.jp...</td>\n",
       "      <td>[0.4912994446435285, 0.012263879203628645, 0.0...</td>\n",
       "      <td>image.4432.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>3</td>\n",
       "      <td>[image.4439.jpg, image.1435.jpg, image.4446.pn...</td>\n",
       "      <td>[0.3407435548358683, 0.14388418060641275, 0.01...</td>\n",
       "      <td>image.1435.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>4</td>\n",
       "      <td>[image.4454.jpg, image.4455.jpg, image.4450.jp...</td>\n",
       "      <td>[0.5767245507579232, 0.0252005534189324, 0.0, ...</td>\n",
       "      <td>image.4455.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>english</td>\n",
       "      <td>458</td>\n",
       "      <td>[image.8063.jpg, image.4891.jpg, image.7450.jp...</td>\n",
       "      <td>[0.2646424995544188, 0.021138835508585776, 0.0...</td>\n",
       "      <td>image.8063.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>english</td>\n",
       "      <td>459</td>\n",
       "      <td>[image.8073.jpg, image.8067.jpg, image.8072.jp...</td>\n",
       "      <td>[0.16073182880838535, 0.13371317099079946, 0.0...</td>\n",
       "      <td>image.8069.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>english</td>\n",
       "      <td>460</td>\n",
       "      <td>[image.8081.jpg, image.8082.jpg, image.8079.jp...</td>\n",
       "      <td>[0.6459736694721107, 0.32025237626459924, 0.0,...</td>\n",
       "      <td>image.8081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>english</td>\n",
       "      <td>461</td>\n",
       "      <td>[image.8087.jpg, image.8089.jpg, image.8088.jp...</td>\n",
       "      <td>[0.3787054468898943, 0.1804472147232383, 0.180...</td>\n",
       "      <td>image.8089.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>english</td>\n",
       "      <td>462</td>\n",
       "      <td>[image.8095.jpg, image.8090.jpg, image.8091.jp...</td>\n",
       "      <td>[0.3423096366579035, 0.12081607829594697, 0.0,...</td>\n",
       "      <td>image.8095.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    language  data                                          candidate  \\\n",
       "0    english     0  [image.2166.jpg, image.4418.jpg, image.4415.jp...   \n",
       "1    english     1  [image.4429.png, image.4427.jpg, image.4422.jp...   \n",
       "2    english     2  [image.4435.jpg, image.4432.jpg, image.4436.jp...   \n",
       "3    english     3  [image.4439.jpg, image.1435.jpg, image.4446.pn...   \n",
       "4    english     4  [image.4454.jpg, image.4455.jpg, image.4450.jp...   \n",
       "..       ...   ...                                                ...   \n",
       "458  english   458  [image.8063.jpg, image.4891.jpg, image.7450.jp...   \n",
       "459  english   459  [image.8073.jpg, image.8067.jpg, image.8072.jp...   \n",
       "460  english   460  [image.8081.jpg, image.8082.jpg, image.8079.jp...   \n",
       "461  english   461  [image.8087.jpg, image.8089.jpg, image.8088.jp...   \n",
       "462  english   462  [image.8095.jpg, image.8090.jpg, image.8091.jp...   \n",
       "\n",
       "                                             relevance            gold  \n",
       "0    [0.34457918364900364, 0.32060663573968956, 0.1...  image.2166.jpg  \n",
       "1    [0.5107523260388563, 0.007055607515222442, 0.0...  image.4429.png  \n",
       "2    [0.4912994446435285, 0.012263879203628645, 0.0...  image.4432.jpg  \n",
       "3    [0.3407435548358683, 0.14388418060641275, 0.01...  image.1435.jpg  \n",
       "4    [0.5767245507579232, 0.0252005534189324, 0.0, ...  image.4455.jpg  \n",
       "..                                                 ...             ...  \n",
       "458  [0.2646424995544188, 0.021138835508585776, 0.0...  image.8063.jpg  \n",
       "459  [0.16073182880838535, 0.13371317099079946, 0.0...  image.8069.jpg  \n",
       "460  [0.6459736694721107, 0.32025237626459924, 0.0,...  image.8081.jpg  \n",
       "461  [0.3787054468898943, 0.1804472147232383, 0.180...  image.8089.jpg  \n",
       "462  [0.3423096366579035, 0.12081607829594697, 0.0,...  image.8095.jpg  \n",
       "\n",
       "[463 rows x 5 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tocsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "19736784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the csv of results\n",
    "result_path = \"Results\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)   \n",
    "result_name =os.path.join(result_path, \"test_sorting4.csv\" )\n",
    "result_tocsv.to_csv(result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c95adb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Results'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b41d05",
   "metadata": {},
   "source": [
    "# Test another classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "66785564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\tree\\tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf2 = tree.DecisionTreeClassifier()\n",
    "clf2 = clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f5d0623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feat = np.zeros((d))\n",
    "matches = np.zeros((df_data.shape[0], 10))\n",
    "for i in range (df_gold.shape[0]):\n",
    "    for j in range (2,df_data.shape[1]):\n",
    "        image_index = df_image_names[df_image_names[\"0\"]==df_data.iloc[i][j]].index.values\n",
    "        featureC = df_image_features.iloc[image_index]\n",
    "        matches[i,j-2]= clf2.predict_proba(featureC.to_numpy(copy=True).reshape(1,-1))[0][i]\n",
    "        \n",
    "matches_df = pd.DataFrame(matches)\n",
    "final_result_images = []\n",
    "final_result_distances = []\n",
    "for idx, row in matches_df.iterrows():\n",
    "    dist_test = row\n",
    "    ranked_dist = -np.sort(-dist_test)\n",
    "    ranked_dist_indices = np.argsort(-dist_test)\n",
    "    sorted_df = np.array(df_data.iloc[idx][ranked_dist_indices+2])\n",
    "    final_result_images.append(sorted_df)\n",
    "    final_result_distances.append(ranked_dist)\n",
    "    \n",
    "result_tocsv = pd.DataFrame()\n",
    "result_tocsv[\"language\"]=[]\n",
    "result_tocsv[\"data\"]=[]\n",
    "result_tocsv[\"candidate\"]=final_result_images\n",
    "result_tocsv[\"relevance\"]=final_result_distances\n",
    "result_tocsv[\"language\"]=language\n",
    "result_tocsv[\"gold\"]=df_gold.values\n",
    "result_tocsv[\"data\"]=range(len(final_result_distances))\n",
    "\n",
    "# save the csv of results\n",
    "result_path = \"Results\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)   \n",
    "    \n",
    "result_name =os.path.join(result_path, \"test_sorting5.csv\" )\n",
    "result_tocsv.to_csv(result_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8451c6",
   "metadata": {},
   "source": [
    "# End of test another classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1ac35",
   "metadata": {},
   "source": [
    "# Test MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c1e7f169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf3 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf3 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1, max_iter=2000)\n",
    "clf3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4e9d266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feat = np.zeros((d))\n",
    "matches = np.zeros((df_data.shape[0], 10))\n",
    "for i in range (df_gold.shape[0]):\n",
    "    for j in range (2,df_data.shape[1]):\n",
    "        image_index = df_image_names[df_image_names[\"0\"]==df_data.iloc[i][j]].index.values\n",
    "        featureC = df_image_features.iloc[image_index]\n",
    "        matches[i,j-2]= clf3.predict_proba(featureC.to_numpy(copy=True).reshape(1,-1))[0][i]\n",
    "        \n",
    "matches_df = pd.DataFrame(matches)\n",
    "final_result_images = []\n",
    "final_result_distances = []\n",
    "for idx, row in matches_df.iterrows():\n",
    "    dist_test = row\n",
    "    ranked_dist = -np.sort(-dist_test)\n",
    "    ranked_dist_indices = np.argsort(-dist_test)\n",
    "    sorted_df = np.array(df_data.iloc[idx][ranked_dist_indices+2])\n",
    "    final_result_images.append(sorted_df)\n",
    "    final_result_distances.append(ranked_dist)\n",
    "    \n",
    "result_tocsv = pd.DataFrame()\n",
    "result_tocsv[\"language\"]=[]\n",
    "result_tocsv[\"data\"]=[]\n",
    "result_tocsv[\"candidate\"]=final_result_images\n",
    "result_tocsv[\"relevance\"]=final_result_distances\n",
    "result_tocsv[\"language\"]=language\n",
    "result_tocsv[\"gold\"]=df_gold.values\n",
    "result_tocsv[\"data\"]=range(len(final_result_distances))\n",
    "\n",
    "# save the csv of results\n",
    "result_path = \"Results\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)   \n",
    "    \n",
    "result_name =os.path.join(result_path, \"test_sorting7.csv\" )\n",
    "result_tocsv.to_csv(result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47f04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ee5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f759ba4",
   "metadata": {},
   "source": [
    "# end of test MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96a756",
   "metadata": {},
   "source": [
    "# try logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1a74e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=6000)\n",
    "lr_clf.fit(X, y)\n",
    "\n",
    "print(round(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "99ef076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feat = np.zeros((d))\n",
    "matches = np.zeros((df_data.shape[0], 10))\n",
    "for i in range (df_gold.shape[0]):\n",
    "    for j in range (2,df_data.shape[1]):\n",
    "        image_index = df_image_names[df_image_names[\"0\"]==df_data.iloc[i][j]].index.values\n",
    "        featureC = df_image_features.iloc[image_index]\n",
    "        matches[i,j-2]= lr_clf.predict_proba(featureC.to_numpy(copy=True).reshape(1,-1))[0][i]\n",
    "        \n",
    "matches_df = pd.DataFrame(matches)\n",
    "final_result_images = []\n",
    "final_result_distances = []\n",
    "for idx, row in matches_df.iterrows():\n",
    "    dist_test = row\n",
    "    ranked_dist = -np.sort(-dist_test)\n",
    "    ranked_dist_indices = np.argsort(-dist_test)\n",
    "    sorted_df = np.array(df_data.iloc[idx][ranked_dist_indices+2])\n",
    "    final_result_images.append(sorted_df)\n",
    "    final_result_distances.append(ranked_dist)\n",
    "    \n",
    "result_tocsv = pd.DataFrame()\n",
    "result_tocsv[\"language\"]=[]\n",
    "result_tocsv[\"data\"]=[]\n",
    "result_tocsv[\"candidate\"]=final_result_images\n",
    "result_tocsv[\"relevance\"]=final_result_distances\n",
    "result_tocsv[\"language\"]=language\n",
    "result_tocsv[\"gold\"]=df_gold.values\n",
    "result_tocsv[\"data\"]=range(len(final_result_distances))\n",
    "\n",
    "# save the csv of results\n",
    "result_path = \"Results\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)   \n",
    "    \n",
    "result_name =os.path.join(result_path, \"test_sorting9.csv\" )\n",
    "result_tocsv.to_csv(result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee04f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "babf7b3f",
   "metadata": {},
   "source": [
    "# End of Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ecf621",
   "metadata": {},
   "source": [
    "# try to train only on the 10 contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd063c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feat = np.zeros((d))\n",
    "df_features = pd.DataFrame()\n",
    "df_labels = pd.DataFrame()\n",
    "for i in range (df_gold.shape[0]):\n",
    "    for j in range(2, df_data.shape[1]):\n",
    "        image_index = df_image_names[df_image_names[\"0\"]==df_data.iloc[i][j]].index.values\n",
    "        featureC = df_image_features.iloc[image_index]\n",
    "        df_features = df_features.append(featureC)\n",
    "        file_scrapped_features = os.path.join(folder_scrapped_features, language, search_engine +\n",
    "                                          \"_\" + str(image_index) + \".csv\") \n",
    "        featureDB = pd.read_csv(file_scrapped_features, delimiter=',')\n",
    "        df_features = df_features.append(featureDB)\n",
    "        \n",
    "        label_index = df_gold[df_gold==df_data.iloc[i][j]].index\n",
    "        df_labels = df_labels.append(pd.DataFrame(np.zeros((featureDB.shape[0]+1))+label_index))\n",
    "    break\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d457d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feat = np.zeros((d))\n",
    "df_labels = pd.DataFrame()\n",
    "for i in range (df_gold.shape[0]):\n",
    "    file_scrapped_features = os.path.join(folder_scrapped_features, language, search_engine +\n",
    "                                          \"_\" + str(i) + \".csv\") \n",
    "    featureDB = pd.read_csv(file_scrapped_features, delimiter=',')\n",
    "    df_labels = df_labels.append(pd.DataFrame(np.zeros((featureDB.shape[0]+1))+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ab118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6249595c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81989b5",
   "metadata": {},
   "source": [
    "# try to train only on the 10 contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "82f17297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 2361 points : 142\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "% (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d4aaa4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ab65132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(X_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f1f06c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65068723, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17487587,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.04341032,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09827369, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02945773, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00329516, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b7635974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506872342006732"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec27ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
