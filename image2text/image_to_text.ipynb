{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "XPx1ENMtMrXj"
   },
   "outputs": [],
   "source": [
    "NAME = \"Aung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNfiEbwop-5o",
    "outputId": "c13ac979-91ba-4d82-d542-3af44060f06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QgQ9pLUxRt_g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 2.8 MB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     -------------------------------------- 268.8/268.8 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp37-cp37m-win_amd64.whl (153 kB)\n",
      "     -------------------------------------- 153.2/153.2 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp37-cp37m-win_amd64.whl (266 kB)\n",
      "     -------------------------------------- 266.4/266.4 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.8.8-cp37-cp37m-win_amd64.whl (268 kB)\n",
      "     -------------------------------------- 268.7/268.7 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from transformers) (6.0.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "     -------------------------------------- 143.0/143.0 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Installing collected packages: tokenizers, safetensors, regex, pyyaml, fsspec, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.2 fsspec-2023.1.0 huggingface-hub-0.16.4 pyyaml-6.0.1 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.30.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 2.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from sentence-transformers) (4.30.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from sentence-transformers) (1.10.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from sentence-transformers) (0.11.0a0)\n",
      "Requirement already satisfied: numpy in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from sentence-transformers) (1.9.3)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp37-cp37m-win_amd64.whl (977 kB)\n",
      "     -------------------------------------- 977.7/977.7 kB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.1.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
      "Requirement already satisfied: click in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from torchvision->sentence-transformers) (9.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\insaf\\anaconda3\\envs\\competition01\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=17844df4b8cb173ccfa07a000faf45cc834242372d2528cf9aa412d2172998d8\n",
      "  Stored in directory: c:\\users\\insaf\\appdata\\local\\pip\\cache\\wheels\\bf\\06\\fb\\d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, nltk, sentence-transformers\n",
      "Successfully installed nltk-3.8.1 sentence-transformers-2.2.2 sentencepiece-0.1.99\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_ZCY-CQ1Rt_h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\utils\\validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "import torch\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "import zipfile\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "gN88OTxfRt_k"
   },
   "outputs": [],
   "source": [
    "PATH = \"/content/drive/MyDrive/SemEval_Data/SplitData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycwd = os.path.dirname(os.getcwd())\n",
    "# flags\n",
    "language = \"english\"\n",
    "#language = \"persian\"\n",
    "#language = \"italian\"\n",
    "search_engine = \"qwant\"\n",
    "search_engines = [\"qwant\", \"bing\", \"ecosia\"]\n",
    "#search_engines = [\"qwant\", \"ecosia\"]\n",
    "\n",
    "# folders\n",
    "folder_images = os.path.join(mycwd, \"0-dataset\", \"test_images\")\n",
    "root_txt =  os.path.join(mycwd, \"0-dataset\", \"test.data.v1.1.gold\")\n",
    "#folder_search = os.path.join(mycwd, \"9-Insaf_scrapSearch\", \"scrape_\"+language, search_engine, \"query\")\n",
    "\n",
    "if language == \"english\":\n",
    "    file_gold = os.path.join(root_txt,\"en.test.gold.v1.1.txt\")\n",
    "    file_data = os.path.join(root_txt,\"en.test.data.v1.1.txt\")\n",
    "elif language == \"persian\":\n",
    "    file_gold = os.path.join(root_txt,\"fa.test.gold.txt\")\n",
    "    file_data = os.path.join(root_txt,\"fa.test.data.txt\")\n",
    "elif language == \"italian\":\n",
    "    file_gold = os.path.join(root_txt,\"it.test.gold.v1.1.txt\")\n",
    "    file_data = os.path.join(root_txt,\"it.test.data.v1.1.txt\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5mX1_42ERt_l",
    "outputId": "e8309660-e04d-4254-c15f-3f2cdfa724c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>goal</td>\n",
       "      <td>football goal</td>\n",
       "      <td>image.4418.jpg</td>\n",
       "      <td>image.4416.jpg</td>\n",
       "      <td>image.4417.jpg</td>\n",
       "      <td>image.4413.jpg</td>\n",
       "      <td>image.4412.jpg</td>\n",
       "      <td>image.4415.jpg</td>\n",
       "      <td>image.4419.jpg</td>\n",
       "      <td>image.4414.jpg</td>\n",
       "      <td>image.2166.jpg</td>\n",
       "      <td>image.1150.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mustard</td>\n",
       "      <td>mustard seed</td>\n",
       "      <td>image.4429.png</td>\n",
       "      <td>image.4422.jpg</td>\n",
       "      <td>image.4423.jpg</td>\n",
       "      <td>image.4424.jpg</td>\n",
       "      <td>image.4421.jpg</td>\n",
       "      <td>image.4427.jpg</td>\n",
       "      <td>image.4426.jpg</td>\n",
       "      <td>image.4420.jpg</td>\n",
       "      <td>image.4425.jpg</td>\n",
       "      <td>image.4428.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seat</td>\n",
       "      <td>eating seat</td>\n",
       "      <td>image.4435.jpg</td>\n",
       "      <td>image.4436.jpg</td>\n",
       "      <td>image.1166.jpg</td>\n",
       "      <td>image.4430.jpg</td>\n",
       "      <td>image.4433.jpg</td>\n",
       "      <td>image.4432.jpg</td>\n",
       "      <td>image.4438.jpg</td>\n",
       "      <td>image.4434.jpg</td>\n",
       "      <td>image.4431.jpg</td>\n",
       "      <td>image.4437.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>navigate</td>\n",
       "      <td>navigate the web</td>\n",
       "      <td>image.4439.jpg</td>\n",
       "      <td>image.4440.jpg</td>\n",
       "      <td>image.4441.jpg</td>\n",
       "      <td>image.4442.jpg</td>\n",
       "      <td>image.4444.jpg</td>\n",
       "      <td>image.4445.jpg</td>\n",
       "      <td>image.1435.jpg</td>\n",
       "      <td>image.4446.png</td>\n",
       "      <td>image.1434.jpg</td>\n",
       "      <td>image.4443.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>butterball</td>\n",
       "      <td>butterball person</td>\n",
       "      <td>image.4454.jpg</td>\n",
       "      <td>image.4450.jpg</td>\n",
       "      <td>image.4455.jpg</td>\n",
       "      <td>image.4453.jpg</td>\n",
       "      <td>image.4448.jpg</td>\n",
       "      <td>image.1253.jpg</td>\n",
       "      <td>image.4451.jpg</td>\n",
       "      <td>image.4452.jpg</td>\n",
       "      <td>image.4447.jpg</td>\n",
       "      <td>image.4449.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                  1               2               3   \\\n",
       "0        goal      football goal  image.4418.jpg  image.4416.jpg   \n",
       "1     mustard       mustard seed  image.4429.png  image.4422.jpg   \n",
       "2        seat        eating seat  image.4435.jpg  image.4436.jpg   \n",
       "3    navigate   navigate the web  image.4439.jpg  image.4440.jpg   \n",
       "4  butterball  butterball person  image.4454.jpg  image.4450.jpg   \n",
       "\n",
       "               4               5               6               7   \\\n",
       "0  image.4417.jpg  image.4413.jpg  image.4412.jpg  image.4415.jpg   \n",
       "1  image.4423.jpg  image.4424.jpg  image.4421.jpg  image.4427.jpg   \n",
       "2  image.1166.jpg  image.4430.jpg  image.4433.jpg  image.4432.jpg   \n",
       "3  image.4441.jpg  image.4442.jpg  image.4444.jpg  image.4445.jpg   \n",
       "4  image.4455.jpg  image.4453.jpg  image.4448.jpg  image.1253.jpg   \n",
       "\n",
       "               8               9               10              11  \n",
       "0  image.4419.jpg  image.4414.jpg  image.2166.jpg  image.1150.jpg  \n",
       "1  image.4426.jpg  image.4420.jpg  image.4425.jpg  image.4428.jpg  \n",
       "2  image.4438.jpg  image.4434.jpg  image.4431.jpg  image.4437.jpg  \n",
       "3  image.1435.jpg  image.4446.png  image.1434.jpg  image.4443.jpg  \n",
       "4  image.4451.jpg  image.4452.jpg  image.4447.jpg  image.4449.jpg  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(file_data, delimiter='\\t', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image.2166.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image.4429.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image.4432.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image.1435.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image.4455.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0  image.2166.jpg\n",
       "1  image.4429.png\n",
       "2  image.4432.jpg\n",
       "3  image.1435.jpg\n",
       "4  image.4455.jpg"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gold = pd.read_csv(file_gold, delimiter='\\t', header=None)\n",
    "df_gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "we2ikpXpHt5A"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ppe0qENMRt_n"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9chN5gNJRt_n"
   },
   "outputs": [],
   "source": [
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3t-jYimtRt_o"
   },
   "source": [
    "#### Generate the description for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_N3FJ1GIofF",
    "outputId": "3eacda0c-29c5-484b-e1c8-1733bfab15c5"
   },
   "outputs": [],
   "source": [
    "img_list_0 = [item[2:] for item in data.values.tolist()]\n",
    "img_list_1 = []\n",
    "for item in img_list_0:\n",
    "    for item2 in item:\n",
    "        img_list_1.append(item2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values / image names\n",
    "img_list = set(img_list_1)\n",
    "img_list = list(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image.5848.jpg',\n",
       " 'image.6307.jpg',\n",
       " 'image.5680.jpg',\n",
       " 'image.4827.jpg',\n",
       " 'image.4469.jpg',\n",
       " 'image.6647.jpg',\n",
       " 'image.7720.jpg',\n",
       " 'image.5895.jpg',\n",
       " 'image.4753.jpg',\n",
       " 'image.7159.jpg',\n",
       " 'image.5363.jpg',\n",
       " 'image.4598.jpg',\n",
       " 'image.7558.jpg',\n",
       " 'image.5443.jpg',\n",
       " 'image.4714.jpg',\n",
       " 'image.6393.jpg',\n",
       " 'image.5414.jpg',\n",
       " 'image.7182.jpg',\n",
       " 'image.3721.jpg',\n",
       " 'image.5507.jpg',\n",
       " 'image.4677.jpg',\n",
       " 'image.6684.JPG',\n",
       " 'image.2435.jpg',\n",
       " 'image.6602.jpg',\n",
       " 'image.4435.jpg',\n",
       " 'image.4480.jpg',\n",
       " 'image.7379.jpg',\n",
       " 'image.5940.jpg',\n",
       " 'image.4477.jpg',\n",
       " 'image.6058.jpg',\n",
       " 'image.5516.jpg',\n",
       " 'image.6524.jpg',\n",
       " 'image.6839.jpg',\n",
       " 'image.5088.jpg',\n",
       " 'image.6038.jpg',\n",
       " 'image.8071.jpg',\n",
       " 'image.7461.jpg',\n",
       " 'image.435.jpg',\n",
       " 'image.7165.jpg',\n",
       " 'image.6100.jpg',\n",
       " 'image.5229.jpg',\n",
       " 'image.6380.jpg',\n",
       " 'image.4657.jpg',\n",
       " 'image.4635.jpg',\n",
       " 'image.5962.jpg',\n",
       " 'image.7380.jpg',\n",
       " 'image.4644.jpg',\n",
       " 'image.257.jpg',\n",
       " 'image.5403.jpg',\n",
       " 'image.5369.jpg',\n",
       " 'image.4767.jpg',\n",
       " 'image.4980.jpg',\n",
       " 'image.7579.jpg',\n",
       " 'image.45.jpg',\n",
       " 'image.3103.jpg',\n",
       " 'image.1376.jpg',\n",
       " 'image.6898.jpg',\n",
       " 'image.5670.jpg',\n",
       " 'image.1080.jpg',\n",
       " 'image.4721.jpg',\n",
       " 'image.4436.jpg',\n",
       " 'image.4494.jpg',\n",
       " 'image.5286.jpg',\n",
       " 'image.4444.jpg',\n",
       " 'image.6538.jpg',\n",
       " 'image.7435.jpg',\n",
       " 'image.5289.jpg',\n",
       " 'image.6506.jpg',\n",
       " 'image.4602.jpg',\n",
       " 'image.4799.jpg',\n",
       " 'image.6494.jpg',\n",
       " 'image.4756.jpg',\n",
       " 'image.684.jpg',\n",
       " 'image.7777.jpg',\n",
       " 'image.7926.jpg',\n",
       " 'image.5672.jpg',\n",
       " 'image.6349.jpg',\n",
       " 'image.7004.jpg',\n",
       " 'image.1023.jpg',\n",
       " 'image.5561.jpg',\n",
       " 'image.4515.jpg',\n",
       " 'image.4681.jpg',\n",
       " 'image.832.jpg',\n",
       " 'image.7473.jpg',\n",
       " 'image.7687.jpg',\n",
       " 'image.4419.jpg',\n",
       " 'image.5996.jpg',\n",
       " 'image.1740.jpg',\n",
       " 'image.6958.jpg',\n",
       " 'image.7487.jpg',\n",
       " 'image.4536.jpg',\n",
       " 'image.5894.jpg',\n",
       " 'image.1452.jpg',\n",
       " 'image.5002.jpg',\n",
       " 'image.5514.jpg',\n",
       " 'image.6446.jpg',\n",
       " 'image.6793.jpg',\n",
       " 'image.6436.jpg',\n",
       " 'image.967.jpg',\n",
       " 'image.2324.jpg',\n",
       " 'image.6450.jpg',\n",
       " 'image.6899.jpg',\n",
       " 'image.869.jpg',\n",
       " 'image.7267.jpg',\n",
       " 'image.7362.jpg',\n",
       " 'image.7557.jpg',\n",
       " 'image.5226.jpg',\n",
       " 'image.7185.png',\n",
       " 'image.4478.jpg',\n",
       " 'image.2063.jpg',\n",
       " 'image.6189.jpg',\n",
       " 'image.7297.jpg',\n",
       " 'image.1911.jpg',\n",
       " 'image.6987.jpg',\n",
       " 'image.5012.jpg',\n",
       " 'image.6267.jpg',\n",
       " 'image.4493.jpg',\n",
       " 'image.6708.jpg',\n",
       " 'image.5397.jpg',\n",
       " 'image.5696.jpg',\n",
       " 'image.5011.jpg',\n",
       " 'image.5405.jpg',\n",
       " 'image.5838.jpg',\n",
       " 'image.4841.jpg',\n",
       " 'image.5825.jpg',\n",
       " 'image.4442.jpg',\n",
       " 'image.8039.jpg',\n",
       " 'image.2749.jpg',\n",
       " 'image.183.jpg',\n",
       " 'image.2123.jpg',\n",
       " 'image.7840.jpg',\n",
       " 'image.4758.jpg',\n",
       " 'image.7539.jpg',\n",
       " 'image.4739.jpg',\n",
       " 'image.4791.jpg',\n",
       " 'image.4828.jpg',\n",
       " 'image.5731.jpg',\n",
       " 'image.6369.jpg',\n",
       " 'image.5629.jpg',\n",
       " 'image.7559.jpg',\n",
       " 'image.7595.jpg',\n",
       " 'image.7629.jpg',\n",
       " 'image.5210.jpg',\n",
       " 'image.4579.jpg',\n",
       " 'image.5804.jpg',\n",
       " 'image.6991.jpg',\n",
       " 'image.7704.jpg',\n",
       " 'image.5657.jpg',\n",
       " 'image.4461.jpg',\n",
       " 'image.6936.jpg',\n",
       " 'image.4669.jpg',\n",
       " 'image.4991.jpg',\n",
       " 'image.5132.jpg',\n",
       " 'image.5417.jpg',\n",
       " 'image.6879.jpg',\n",
       " 'image.5655.jpg',\n",
       " 'image.4770.jpg',\n",
       " 'image.4938.jpg',\n",
       " 'image.6521.jpg',\n",
       " 'image.275.jpg',\n",
       " 'image.7276.jpg',\n",
       " 'image.6584.jpg',\n",
       " 'image.4820.jpg',\n",
       " 'image.7359.jpg',\n",
       " 'image.7985.jpg',\n",
       " 'image.7666.jpg',\n",
       " 'image.7021.jpg',\n",
       " 'image.5384.jpg',\n",
       " 'image.5225.jpg',\n",
       " 'image.5734.jpg',\n",
       " 'image.4667.jpg',\n",
       " 'image.5075.jpg',\n",
       " 'image.4452.jpg',\n",
       " 'image.2150.jpg',\n",
       " 'image.5765.jpg',\n",
       " 'image.594.jpg',\n",
       " 'image.4811.jpg',\n",
       " 'image.4577.jpg',\n",
       " 'image.4643.jpg',\n",
       " 'image.4971.jpg',\n",
       " 'image.7514.jpg',\n",
       " 'image.5338.jpg',\n",
       " 'image.6590.jpg',\n",
       " 'image.5865.jpg',\n",
       " 'image.5849.jpg',\n",
       " 'image.4460.jpg',\n",
       " 'image.5725.jpg',\n",
       " 'image.7639.jpg',\n",
       " 'image.7737.jpg',\n",
       " 'image.4618.jpg',\n",
       " 'image.5702.jpg',\n",
       " 'image.4918.jpg',\n",
       " 'image.5971.jpg',\n",
       " 'image.4616.jpg',\n",
       " 'image.7027.png',\n",
       " 'image.5280.jpg',\n",
       " 'image.5927.jpg',\n",
       " 'image.7771.jpg',\n",
       " 'image.5071.jpg',\n",
       " 'image.4809.jpg',\n",
       " 'image.5979.jpg',\n",
       " 'image.7219.jpg',\n",
       " 'image.5943.jpg',\n",
       " 'image.7178.jpg',\n",
       " 'image.7221.jpg',\n",
       " 'image.5373.jpg',\n",
       " 'image.6753.png',\n",
       " 'image.6516.jpg',\n",
       " 'image.5483.jpg',\n",
       " 'image.6519.jpg',\n",
       " 'image.6823.jpg',\n",
       " 'image.7101.jpg',\n",
       " 'image.7655.jpg',\n",
       " 'image.7849.jpg',\n",
       " 'image.6785.jpg',\n",
       " 'image.6560.jpg',\n",
       " 'image.5834.jpg',\n",
       " 'image.4716.jpg',\n",
       " 'image.7305.jpg',\n",
       " 'image.7647.jpg',\n",
       " 'image.7028.jpg',\n",
       " 'image.7643.jpg',\n",
       " 'image.5325.jpg',\n",
       " 'image.7512.jpg',\n",
       " 'image.7919.jpg',\n",
       " 'image.6663.jpg',\n",
       " 'image.5233.jpg',\n",
       " 'image.7954.jpg',\n",
       " 'image.7224.jpg',\n",
       " 'image.7265.jpg',\n",
       " 'image.6713.jpg',\n",
       " 'image.139.jpg',\n",
       " 'image.5783.jpg',\n",
       " 'image.7000.jpg',\n",
       " 'image.5557.jpg',\n",
       " 'image.7234.jpg',\n",
       " 'image.2086.jpg',\n",
       " 'image.4850.jpg',\n",
       " 'image.6664.jpg',\n",
       " 'image.6927.jpg',\n",
       " 'image.2915.jpg',\n",
       " 'image.7268.jpg',\n",
       " 'image.7333.jpg',\n",
       " 'image.7484.jpg',\n",
       " 'image.4665.png',\n",
       " 'image.7361.jpg',\n",
       " 'image.5905.jpg',\n",
       " 'image.4766.jpg',\n",
       " 'image.4599.jpg',\n",
       " 'image.5170.jpg',\n",
       " 'image.4930.jpg',\n",
       " 'image.7781.jpg',\n",
       " 'image.1794.jpg',\n",
       " 'image.6500.png',\n",
       " 'image.7472.jpg',\n",
       " 'image.6403.jpg',\n",
       " 'image.7725.jpg',\n",
       " 'image.7948.jpg',\n",
       " 'image.1730.jpg',\n",
       " 'image.4525.jpg',\n",
       " 'image.486.jpg',\n",
       " 'image.8057.jpg',\n",
       " 'image.5192.jpg',\n",
       " 'image.2223.jpg',\n",
       " 'image.5134.jpg',\n",
       " 'image.5251.jpg',\n",
       " 'image.5520.jpg',\n",
       " 'image.6677.jpg',\n",
       " 'image.7189.jpg',\n",
       " 'image.49.jpg',\n",
       " 'image.7765.jpg',\n",
       " 'image.4465.jpg',\n",
       " 'image.5661.jpg',\n",
       " 'image.5216.jpg',\n",
       " 'image.5345.jpg',\n",
       " 'image.5276.jpg',\n",
       " 'image.6525.jpg',\n",
       " 'image.6529.jpg',\n",
       " 'image.7416.jpg',\n",
       " 'image.2574.jpg',\n",
       " 'image.614.jpg',\n",
       " 'image.5356.jpg',\n",
       " 'image.5554.jpg',\n",
       " 'image.7318.jpg',\n",
       " 'image.1604.jpg',\n",
       " 'image.4497.jpg',\n",
       " 'image.1780.jpg',\n",
       " 'image.1469.jpg',\n",
       " 'image.5740.png',\n",
       " 'image.7634.jpg',\n",
       " 'image.4902.jpg',\n",
       " 'image.7227.jpg',\n",
       " 'image.5551.jpg',\n",
       " 'image.5570.jpg',\n",
       " 'image.6660.jpg',\n",
       " 'image.6463.jpg',\n",
       " 'image.4795.jpg',\n",
       " 'image.6214.jpg',\n",
       " 'image.6955.jpg',\n",
       " 'image.6221.jpg',\n",
       " 'image.7850.jpg',\n",
       " 'image.8018.jpg',\n",
       " 'image.7465.jpg',\n",
       " 'image.6284.jpg',\n",
       " 'image.4784.jpg',\n",
       " 'image.7887.jpg',\n",
       " 'image.7938.jpg',\n",
       " 'image.5279.png',\n",
       " 'image.7002.jpg',\n",
       " 'image.5525.jpg',\n",
       " 'image.6492.jpg',\n",
       " 'image.5677.jpg',\n",
       " 'image.5256.jpg',\n",
       " 'image.5314.jpg',\n",
       " 'image.2148.jpg',\n",
       " 'image.6049.jpg',\n",
       " 'image.6131.jpg',\n",
       " 'image.6188.png',\n",
       " 'image.4839.jpg',\n",
       " 'image.7763.jpg',\n",
       " 'image.7432.jpg',\n",
       " 'image.7873.jpg',\n",
       " 'image.5564.jpg',\n",
       " 'image.5906.jpg',\n",
       " 'image.4704.jpg',\n",
       " 'image.3531.jpg',\n",
       " 'image.4512.jpg',\n",
       " 'image.4800.jpg',\n",
       " 'image.5357.jpg',\n",
       " 'image.5222.jpg',\n",
       " 'image.7284.jpg',\n",
       " 'image.7582.jpg',\n",
       " 'image.5337.jpg',\n",
       " 'image.2777.jpg',\n",
       " 'image.1284.jpg',\n",
       " 'image.1475.jpg',\n",
       " 'image.7868.jpg',\n",
       " 'image.5336.jpg',\n",
       " 'image.6725.jpg',\n",
       " 'image.5816.jpg',\n",
       " 'image.4992.jpg',\n",
       " 'image.7133.jpg',\n",
       " 'image.6681.jpg',\n",
       " 'image.8079.jpg',\n",
       " 'image.7814.jpg',\n",
       " 'image.6784.jpg',\n",
       " 'image.5910.jpg',\n",
       " 'image.226.jpg',\n",
       " 'image.7458.jpg',\n",
       " 'image.7538.jpg',\n",
       " 'image.7646.jpg',\n",
       " 'image.7767.jpg',\n",
       " 'image.6970.jpg',\n",
       " 'image.5016.jpg',\n",
       " 'image.7660.jpg',\n",
       " 'image.7047.jpg',\n",
       " 'image.7110.jpg',\n",
       " 'image.6913.jpg',\n",
       " 'image.2026.jpg',\n",
       " 'image.5547.jpg',\n",
       " 'image.6644.jpg',\n",
       " 'image.741.jpg',\n",
       " 'image.5517.jpg',\n",
       " 'image.2097.jpg',\n",
       " 'image.4481.jpg',\n",
       " 'image.7411.jpg',\n",
       " 'image.7776.jpg',\n",
       " 'image.5208.jpg',\n",
       " 'image.307.jpg',\n",
       " 'image.5772.jpg',\n",
       " 'image.4569.jpg',\n",
       " 'image.2583.jpg',\n",
       " 'image.1658.jpg',\n",
       " 'image.7489.jpg',\n",
       " 'image.92.jpg',\n",
       " 'image.5416.jpg',\n",
       " 'image.1870.jpg',\n",
       " 'image.5331.jpg',\n",
       " 'image.6499.jpg',\n",
       " 'image.6940.jpg',\n",
       " 'image.7030.jpg',\n",
       " 'image.4924.jpg',\n",
       " 'image.21.jpg',\n",
       " 'image.3671.jpg',\n",
       " 'image.7442.jpg',\n",
       " 'image.5468.jpg',\n",
       " 'image.7281.jpg',\n",
       " 'image.7944.jpg',\n",
       " 'image.5457.jpg',\n",
       " 'image.7070.jpg',\n",
       " 'image.5503.jpg',\n",
       " 'image.7067.jpg',\n",
       " 'image.7294.jpg',\n",
       " 'image.7324.jpg',\n",
       " 'image.7503.jpg',\n",
       " 'image.2518.jpg',\n",
       " 'image.5796.jpg',\n",
       " 'image.6582.jpg',\n",
       " 'image.6014.jpg',\n",
       " 'image.2540.jpg',\n",
       " 'image.6167.jpg',\n",
       " 'image.7870.jpg',\n",
       " 'image.4587.jpg',\n",
       " 'image.5878.jpg',\n",
       " 'image.7691.jpg',\n",
       " 'image.5667.jpg',\n",
       " 'image.7235.jpg',\n",
       " 'image.4713.jpg',\n",
       " 'image.7024.jpg',\n",
       " 'image.7420.jpg',\n",
       " 'image.6857.jpg',\n",
       " 'image.4996.png',\n",
       " 'image.6213.jpg',\n",
       " 'image.6198.jpg',\n",
       " 'image.5431.jpg',\n",
       " 'image.4554.jpg',\n",
       " 'image.215.jpg',\n",
       " 'image.7395.jpg',\n",
       " 'image.6574.jpg',\n",
       " 'image.6424.jpg',\n",
       " 'image.4607.jpg',\n",
       " 'image.6655.jpg',\n",
       " 'image.5668.jpg',\n",
       " 'image.7049.jpg',\n",
       " 'image.6867.jpg',\n",
       " 'image.5915.jpg',\n",
       " 'image.5353.jpg',\n",
       " 'image.5542.jpg',\n",
       " 'image.6691.jpg',\n",
       " 'image.5755.jpg',\n",
       " 'image.7290.jpg',\n",
       " 'image.7689.jpg',\n",
       " 'image.4682.jpg',\n",
       " 'image.7307.jpg',\n",
       " 'image.4879.jpg',\n",
       " 'image.6279.jpg',\n",
       " 'image.6475.jpg',\n",
       " 'image.4578.jpg',\n",
       " 'image.5491.jpg',\n",
       " 'image.7236.jpg',\n",
       " 'image.874.jpg',\n",
       " 'image.5249.jpg',\n",
       " 'image.510.jpg',\n",
       " 'image.7792.jpg',\n",
       " 'image.6737.jpg',\n",
       " 'image.7874.jpg',\n",
       " 'image.7509.jpg',\n",
       " 'image.4564.jpg',\n",
       " 'image.5964.jpg',\n",
       " 'image.7467.jpg',\n",
       " 'image.7560.jpg',\n",
       " 'image.7987.jpg',\n",
       " 'image.4765.jpg',\n",
       " 'image.4538.jpg',\n",
       " 'image.7256.jpg',\n",
       " 'image.6589.jpg',\n",
       " 'image.5688.jpg',\n",
       " 'image.6794.jpg',\n",
       " 'image.1020.jpg',\n",
       " 'image.5435.jpg',\n",
       " 'image.7244.jpg',\n",
       " 'image.1.jpg',\n",
       " 'image.7698.jpg',\n",
       " 'image.4835.jpg',\n",
       " 'image.6656.jpg',\n",
       " 'image.7326.jpg',\n",
       " 'image.7684.jpg',\n",
       " 'image.7249.jpg',\n",
       " 'image.5617.jpg',\n",
       " 'image.5237.jpg',\n",
       " 'image.7134.jpg',\n",
       " 'image.6076.jpg',\n",
       " 'image.7955.jpg',\n",
       " 'image.8034.jpg',\n",
       " 'image.6182.jpg',\n",
       " 'image.5368.jpg',\n",
       " 'image.6472.jpg',\n",
       " 'image.6791.jpg',\n",
       " 'image.6974.jpg',\n",
       " 'image.6925.jpg',\n",
       " 'image.6968.jpg',\n",
       " 'image.4457.jpg',\n",
       " 'image.8006.jpg',\n",
       " 'image.6734.jpg',\n",
       " 'image.6892.jpg',\n",
       " 'image.6093.jpg',\n",
       " 'image.7608.jpg',\n",
       " 'image.5206.jpg',\n",
       " 'image.7730.jpg',\n",
       " 'image.7794.jpg',\n",
       " 'image.515.jpg',\n",
       " 'image.5536.jpg',\n",
       " 'image.5776.jpg',\n",
       " 'image.7750.jpg',\n",
       " 'image.5040.jpg',\n",
       " 'image.5460.jpg',\n",
       " 'image.7622.jpg',\n",
       " 'image.6977.jpg',\n",
       " 'image.4550.jpg',\n",
       " 'image.7480.jpg',\n",
       " 'image.4486.jpg',\n",
       " 'image.4874.jpg',\n",
       " 'image.4997.jpg',\n",
       " 'image.5871.jpg',\n",
       " 'image.5060.jpg',\n",
       " 'image.5165.jpg',\n",
       " 'image.6012.jpg',\n",
       " 'image.4505.jpg',\n",
       " 'image.4740.jpg',\n",
       " 'image.1073.jpg',\n",
       " 'image.6754.jpg',\n",
       " 'image.7997.jpg',\n",
       " 'image.4844.jpg',\n",
       " 'image.7233.jpg',\n",
       " 'image.5689.jpg',\n",
       " 'image.6102.jpg',\n",
       " 'image.1381.jpg',\n",
       " 'image.4979.jpg',\n",
       " 'image.5057.jpg',\n",
       " 'image.5145.jpg',\n",
       " 'image.6108.jpg',\n",
       " 'image.7329.jpg',\n",
       " 'image.5775.jpg',\n",
       " 'image.7816.jpg',\n",
       " 'image.5359.jpg',\n",
       " 'image.4699.jpg',\n",
       " 'image.5750.jpg',\n",
       " 'image.7414.jpg',\n",
       " 'image.5275.jpg',\n",
       " 'image.7711.jpg',\n",
       " 'image.7805.jpg',\n",
       " 'image.6618.jpg',\n",
       " 'image.7841.jpg',\n",
       " 'image.6503.jpg',\n",
       " 'image.6216.jpg',\n",
       " 'image.5176.jpg',\n",
       " 'image.640.jpg',\n",
       " 'image.7755.jpg',\n",
       " 'image.5953.jpg',\n",
       " 'image.7680.jpg',\n",
       " 'image.5265.jpg',\n",
       " 'image.6087.jpg',\n",
       " 'image.5903.jpg',\n",
       " 'image.5078.jpg',\n",
       " 'image.7216.jpg',\n",
       " 'image.8065.jpg',\n",
       " 'image.5919.jpg',\n",
       " 'image.4697.jpg',\n",
       " 'image.6164.jpg',\n",
       " 'image.6835.jpg',\n",
       " 'image.5852.jpg',\n",
       " 'image.7193.jpg',\n",
       " 'image.8064.jpg',\n",
       " 'image.6319.jpg',\n",
       " 'image.7804.jpg',\n",
       " 'image.6860.jpg',\n",
       " 'image.6540.jpg',\n",
       " 'image.5151.jpg',\n",
       " 'image.5723.jpg',\n",
       " 'image.5236.jpg',\n",
       " 'image.7590.jpg',\n",
       " 'image.5207.jpg',\n",
       " 'image.6281.jpg',\n",
       " 'image.5674.jpg',\n",
       " 'image.5933.jpg',\n",
       " 'image.5995.jpg',\n",
       " 'image.5541.jpg',\n",
       " 'image.7756.jpg',\n",
       " 'image.6642.jpg',\n",
       " 'image.7943.jpg',\n",
       " 'image.5579.jpeg',\n",
       " 'image.6984.jpg',\n",
       " 'image.6896.jpg',\n",
       " 'image.6184.jpg',\n",
       " 'image.6056.jpg',\n",
       " 'image.6533.jpg',\n",
       " 'image.6143.jpg',\n",
       " 'image.7152.jpg',\n",
       " 'image.7336.jpg',\n",
       " 'image.7019.jpg',\n",
       " 'image.4354.jpg',\n",
       " 'image.7969.jpg',\n",
       " 'image.4988.jpg',\n",
       " 'image.5175.jpg',\n",
       " 'image.7171.jpg',\n",
       " 'image.6571.jpg',\n",
       " 'image.7626.jpg',\n",
       " 'image.5866.jpg',\n",
       " 'image.248.jpg',\n",
       " 'image.6906.jpg',\n",
       " 'image.5272.jpg',\n",
       " 'image.4754.jpg',\n",
       " 'image.6611.jpg',\n",
       " 'image.7466.png',\n",
       " 'image.6967.jpg',\n",
       " 'image.7176.jpg',\n",
       " 'image.7406.jpg',\n",
       " 'image.6759.jpg',\n",
       " 'image.7089.jpg',\n",
       " 'image.5902.jpg',\n",
       " 'image.5760.jpg',\n",
       " 'image.172.jpg',\n",
       " 'image.1619.jpg',\n",
       " 'image.8062.jpg',\n",
       " 'image.4622.jpg',\n",
       " 'image.6617.jpg',\n",
       " 'image.2612.jpg',\n",
       " 'image.4433.jpg',\n",
       " 'image.5213.jpg',\n",
       " 'image.4807.jpg',\n",
       " 'image.4611.jpg',\n",
       " 'image.6396.jpg',\n",
       " 'image.7452.jpg',\n",
       " 'image.5284.jpg',\n",
       " 'image.7338.jpg',\n",
       " 'image.5283.jpg',\n",
       " 'image.4627.jpg',\n",
       " 'image.7483.jpg',\n",
       " 'image.7370.jpg',\n",
       " 'image.4666.jpg',\n",
       " 'image.8017.jpg',\n",
       " 'image.4821.jpg',\n",
       " 'image.6194.jpg',\n",
       " 'image.5534.jpg',\n",
       " 'image.6263.jpg',\n",
       " 'image.6615.jpg',\n",
       " 'image.6113.jpg',\n",
       " 'image.6382.jpg',\n",
       " 'image.6124.jpg',\n",
       " 'image.6920.jpg',\n",
       " 'image.7068.jpg',\n",
       " 'image.5853.jpg',\n",
       " 'image.5454.jpg',\n",
       " 'image.7576.jpg',\n",
       " 'image.1292.jpg',\n",
       " 'image.4732.jpg',\n",
       " 'image.6285.jpg',\n",
       " 'image.7137.jpg',\n",
       " 'image.6552.jpg',\n",
       " 'image.4427.jpg',\n",
       " 'image.7540.jpg',\n",
       " 'image.6863.jpg',\n",
       " 'image.5799.jpg',\n",
       " 'image.6912.jpg',\n",
       " 'image.7549.jpg',\n",
       " 'image.6961.jpg',\n",
       " 'image.5045.jpg',\n",
       " 'image.2028.jpg',\n",
       " 'image.4957.jpg',\n",
       " 'image.6264.jpg',\n",
       " 'image.7752.jpg',\n",
       " 'image.7594.jpg',\n",
       " 'image.5555.jpg',\n",
       " 'image.4603.jpg',\n",
       " 'image.8078.jpg',\n",
       " 'image.6078.jpg',\n",
       " 'image.6746.jpg',\n",
       " 'image.152.jpg',\n",
       " 'image.4842.jpg',\n",
       " 'image.5593.jpg',\n",
       " 'image.6840.jpg',\n",
       " 'image.1142.jpg',\n",
       " 'image.6407.jpg',\n",
       " 'image.6234.jpg',\n",
       " 'image.4917.jpg',\n",
       " 'image.7343.jpg',\n",
       " 'image.4601.jpg',\n",
       " 'image.4813.jpg',\n",
       " 'image.5982.jpg',\n",
       " 'image.6526.jpg',\n",
       " 'image.6083.jpg',\n",
       " 'image.4780.jpg',\n",
       " 'image.8009.jpg',\n",
       " 'image.4759.jpg',\n",
       " 'image.6510.jpg',\n",
       " 'image.4731.jpg',\n",
       " 'image.820.jpg',\n",
       " 'image.2031.jpg',\n",
       " 'image.5395.jpg',\n",
       " 'image.7565.jpg',\n",
       " 'image.4768.jpg',\n",
       " 'image.5015.jpg',\n",
       " 'image.6572.jpg',\n",
       " 'image.6166.jpg',\n",
       " 'image.7561.jpg',\n",
       " 'image.5091.jpg',\n",
       " 'image.8086.jpg',\n",
       " 'image.5348.jpg',\n",
       " 'image.216.jpg',\n",
       " 'image.5118.jpg',\n",
       " 'image.5344.jpg',\n",
       " 'image.6763.jpg',\n",
       " 'image.7225.jpg',\n",
       " 'image.6106.jpg',\n",
       " 'image.178.jpg',\n",
       " 'image.5585.jpg',\n",
       " 'image.5238.jpg',\n",
       " 'image.5671.jpg',\n",
       " 'image.6253.jpg',\n",
       " 'image.454.jpg',\n",
       " 'image.6916.jpg',\n",
       " 'image.225.jpg',\n",
       " 'image.5669.jpg',\n",
       " 'image.6628.jpg',\n",
       " 'image.5488.jpg',\n",
       " 'image.1923.jpg',\n",
       " 'image.662.jpg',\n",
       " 'image.7820.jpg',\n",
       " 'image.5583.jpg',\n",
       " 'image.6050.jpg',\n",
       " 'image.336.jpg',\n",
       " 'image.4715.jpg',\n",
       " 'image.7293.jpg',\n",
       " 'image.1136.jpg',\n",
       " 'image.2629.jpg',\n",
       " 'image.6219.jpg',\n",
       " 'image.5951.jpg',\n",
       " 'image.6953.jpg',\n",
       " 'image.4425.jpg',\n",
       " 'image.5993.jpg',\n",
       " 'image.7773.jpg',\n",
       " 'image.5987.jpg',\n",
       " 'image.4746.jpg',\n",
       " 'image.5247.jpg',\n",
       " 'image.6740.jpg',\n",
       " 'image.7982.jpg',\n",
       " 'image.4338.jpg',\n",
       " 'image.7736.jpg',\n",
       " 'image.8088.jpg',\n",
       " 'image.6091.jpg',\n",
       " 'image.5562.jpg',\n",
       " 'image.5683.jpg',\n",
       " 'image.4535.jpg',\n",
       " 'image.7810.jpg',\n",
       " 'image.6909.jpg',\n",
       " 'image.5387.jpg',\n",
       " 'image.6246.jpg',\n",
       " 'image.6465.jpg',\n",
       " 'image.6484.jpg',\n",
       " 'image.4969.jpg',\n",
       " 'image.1733.jpg',\n",
       " 'image.4434.jpg',\n",
       " 'image.6238.jpg',\n",
       " 'image.6370.jpg',\n",
       " 'image.6421.jpg',\n",
       " 'image.5177.png',\n",
       " 'image.5119.jpg',\n",
       " 'image.950.jpg',\n",
       " 'image.4605.jpg',\n",
       " 'image.6270.jpg',\n",
       " 'image.5475.jpg',\n",
       " 'image.5742.jpg',\n",
       " 'image.5820.jpg',\n",
       " 'image.7080.jpg',\n",
       " 'image.5270.jpg',\n",
       " 'image.6413.jpg',\n",
       " 'image.7918.jpg',\n",
       " 'image.4863.jpg',\n",
       " 'image.6918.jpg',\n",
       " 'image.4840.jpg',\n",
       " 'image.7898.jpg',\n",
       " 'image.6992.jpg',\n",
       " 'image.5199.jpg',\n",
       " 'image.6903.jpg',\n",
       " 'image.7179.jpg',\n",
       " 'image.6207.jpg',\n",
       " 'image.7914.jpg',\n",
       " 'image.7376.jpg',\n",
       " 'image.5890.jpg',\n",
       " 'image.4693.jpg',\n",
       " 'image.2043.jpg',\n",
       " 'image.8027.jpg',\n",
       " 'image.120.jpg',\n",
       " 'image.6187.jpg',\n",
       " 'image.1068.jpg',\n",
       " 'image.6949.jpg',\n",
       " 'image.7494.jpg',\n",
       " 'image.7933.jpg',\n",
       " 'image.6676.jpg',\n",
       " 'image.5808.png',\n",
       " 'image.6880.jpg',\n",
       " 'image.6438.jpg',\n",
       " 'image.7371.jpg',\n",
       " 'image.7803.jpg',\n",
       " 'image.4474.jpg',\n",
       " 'image.5835.jpg',\n",
       " 'image.6353.jpg',\n",
       " 'image.7977.jpg',\n",
       " 'image.7315.jpg',\n",
       " 'image.4580.jpg',\n",
       " 'image.6685.jpg',\n",
       " 'image.3959.jpg',\n",
       " 'image.2584.jpg',\n",
       " 'image.688.jpg',\n",
       " 'image.8051.jpg',\n",
       " 'image.5635.jpg',\n",
       " 'image.7340.jpg',\n",
       " 'image.7441.jpg',\n",
       " 'image.6826.jpg',\n",
       " 'image.6458.jpg',\n",
       " 'image.6922.jpg',\n",
       " 'image.7083.jpg',\n",
       " 'image.6414.jpg',\n",
       " 'image.7106.jpg',\n",
       " 'image.4860.jpg',\n",
       " 'image.5370.jpg',\n",
       " 'image.5886.jpg',\n",
       " 'image.7917.jpg',\n",
       " 'image.4642.jpg',\n",
       " 'image.6716.jpg',\n",
       " 'image.7309.jpg',\n",
       " 'image.7759.jpg',\n",
       " 'image.7107.jpg',\n",
       " 'image.5323.jpg',\n",
       " 'image.6779.jpg',\n",
       " 'image.2356.jpg',\n",
       " 'image.5705.jpg',\n",
       " 'image.4900.jpg',\n",
       " 'image.4760.jpg',\n",
       " 'image.6907.jpg',\n",
       " 'image.5148.jpg',\n",
       " 'image.5856.jpg',\n",
       " 'image.6741.jpg',\n",
       " 'image.3873.jpg',\n",
       " 'image.6830.jpg',\n",
       " 'image.4942.png',\n",
       " 'image.7212.jpg',\n",
       " 'image.7880.jpg',\n",
       " 'image.6399.jpg',\n",
       " 'image.7356.jpg',\n",
       " 'image.1394.jpg',\n",
       " 'image.6265.jpg',\n",
       " 'image.8043.jpg',\n",
       " 'image.4645.jpg',\n",
       " 'image.7381.jpg',\n",
       " 'image.4887.jpg',\n",
       " 'image.5300.jpg',\n",
       " 'image.6983.jpg',\n",
       " 'image.4619.jpg',\n",
       " 'image.6141.jpg',\n",
       " 'image.7292.jpg',\n",
       " 'image.4543.jpg',\n",
       " 'image.5157.jpg',\n",
       " 'image.7282.jpg',\n",
       " 'image.4418.jpg',\n",
       " 'image.7630.jpg',\n",
       " 'image.4510.jpg',\n",
       " 'image.3233.jpg',\n",
       " 'image.5094.jpg',\n",
       " 'image.4553.jpg',\n",
       " 'image.7055.jpg',\n",
       " 'image.5901.jpg',\n",
       " 'image.7633.jpg',\n",
       " 'image.6789.jpg',\n",
       " 'image.5658.jpg',\n",
       " 'image.4596.jpg',\n",
       " 'image.4620.jpg',\n",
       " 'image.7023.jpg',\n",
       " 'image.5043.jpg',\n",
       " 'image.6133.jpg',\n",
       " 'image.7255.jpg',\n",
       " 'image.6902.jpg',\n",
       " 'image.5333.jpg',\n",
       " 'image.7614.jpg',\n",
       " 'image.6482.jpg',\n",
       " 'image.7254.jpg',\n",
       " 'image.7314.jpg',\n",
       " 'image.6372.jpg',\n",
       " 'image.7791.jpg',\n",
       " 'image.1310.jpg',\n",
       " 'image.4671.jpg',\n",
       " 'image.6766.jpg',\n",
       " 'image.6811.jpg',\n",
       " 'image.6148.jpg',\n",
       " 'image.6374.jpg',\n",
       " 'image.4518.jpg',\n",
       " 'image.5659.jpg',\n",
       " 'image.5721.jpg',\n",
       " 'image.6318.jpg',\n",
       " 'image.4482.jpg',\n",
       " 'image.6351.jpg',\n",
       " 'image.5708.jpg',\n",
       " 'image.5125.jpg',\n",
       " 'image.5991.jpg',\n",
       " 'image.4484.jpg',\n",
       " 'image.6624.jpg',\n",
       " 'image.3790.jpg',\n",
       " 'image.5509.jpg',\n",
       " 'image.7656.jpg',\n",
       " 'image.5084.jpg',\n",
       " 'image.1415.jpg',\n",
       " 'image.7052.jpg',\n",
       " 'image.5899.jpg',\n",
       " 'image.5948.jpg',\n",
       " 'image.6373.jpg',\n",
       " 'image.5263.jpg',\n",
       " 'image.5285.jpg',\n",
       " 'image.5389.jpg',\n",
       " 'image.5756.jpg',\n",
       " 'image.5138.jpg',\n",
       " 'image.5250.jpg',\n",
       " 'image.4948.jpg',\n",
       " 'image.3275.jpg',\n",
       " 'image.6110.jpg',\n",
       " 'image.6249.jpg',\n",
       " 'image.7162.jpg',\n",
       " 'image.153.jpg',\n",
       " 'image.7891.jpg',\n",
       " 'image.3186.jpg',\n",
       " 'image.4742.jpg',\n",
       " 'image.7260.jpg',\n",
       " 'image.5465.jpg',\n",
       " 'image.5158.jpg',\n",
       " 'image.4413.jpg',\n",
       " 'image.5508.jpg',\n",
       " 'image.7949.jpg',\n",
       " 'image.170.jpg',\n",
       " 'image.817.jpg',\n",
       " 'image.4676.jpg',\n",
       " 'image.6082.jpg',\n",
       " 'image.4955.jpg',\n",
       " 'image.7688.jpg',\n",
       " 'image.7115.jpg',\n",
       " 'image.4566.jpg',\n",
       " 'image.6757.jpg',\n",
       " 'image.4632.jpg',\n",
       " 'image.6409.jpg',\n",
       " 'image.5305.jpg',\n",
       " 'image.7872.jpg',\n",
       " 'image.6360.jpg',\n",
       " 'image.7166.jpg',\n",
       " 'image.7712.jpg',\n",
       " 'image.7877.jpg',\n",
       " 'image.6838.jpg',\n",
       " 'image.7373.jpg',\n",
       " 'image.4630.jpg',\n",
       " 'image.3818.jpg',\n",
       " 'image.6893.jpg',\n",
       " 'image.5411.jpg',\n",
       " 'image.6630.jpg',\n",
       " 'image.7920.jpg',\n",
       " 'image.6202.jpg',\n",
       " 'image.3587.jpg',\n",
       " 'image.6412.jpg',\n",
       " 'image.7573.jpg',\n",
       " 'image.5421.jpg',\n",
       " 'image.4977.jpg',\n",
       " 'image.5277.jpg',\n",
       " 'image.8001.jpg',\n",
       " 'image.5260.png',\n",
       " 'image.7831.jpg',\n",
       " 'image.4654.jpg',\n",
       " 'image.5950.jpg',\n",
       " 'image.5473.jpg',\n",
       " 'image.5400.jpg',\n",
       " 'image.5859.jpg',\n",
       " 'image.7053.jpg',\n",
       " 'image.7637.jpg',\n",
       " 'image.7566.jpg',\n",
       " 'image.6795.jpg',\n",
       " 'image.4555.jpg',\n",
       " 'image.4470.jpg',\n",
       " 'image.5453.jpg',\n",
       " 'image.7092.jpg',\n",
       " 'image.6150.jpg',\n",
       " 'image.7672.jpg',\n",
       " 'image.4586.jpg',\n",
       " 'image.5183.jpg',\n",
       " 'image.6643.jpg',\n",
       " 'image.5624.jpg',\n",
       " 'image.857.jpg',\n",
       " 'image.5887.jpg',\n",
       " 'image.7258.jpg',\n",
       " 'image.7967.jpg',\n",
       " 'image.7096.jpg',\n",
       " 'image.5879.jpg',\n",
       " 'image.6160.jpg',\n",
       " 'image.4945.jpg',\n",
       " 'image.7963.jpg',\n",
       " 'image.4897.jpg',\n",
       " 'image.5863.jpg',\n",
       " 'image.5116.jpg',\n",
       " 'image.6752.jpg',\n",
       " 'image.5156.jpg',\n",
       " 'image.7061.jpg',\n",
       " 'image.7677.jpg',\n",
       " 'image.4631.jpg',\n",
       " 'image.7351.jpg',\n",
       " 'image.6989.jpg',\n",
       " 'image.6170.jpg',\n",
       " 'image.5100.jpg',\n",
       " 'image.6812.png',\n",
       " 'image.1371.jpg',\n",
       " 'image.6619.jpg',\n",
       " 'image.5028.jpg',\n",
       " 'image.6030.jpg',\n",
       " 'image.6235.jpg',\n",
       " 'image.6293.jpg',\n",
       " 'image.6410.jpg',\n",
       " 'image.5055.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipFile = zipfile.ZipFile(\"/content/drive/MyDrive/semeval-2023-task-1-V-WSD-train-v1.zip\")\n",
    "IMG_PATH = \"semeval-2023-task-1-V-WSD-train-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "kwqUASzsRt_o"
   },
   "outputs": [],
   "source": [
    "def get_images_description(image_path, image_names):\n",
    "    images = list()\n",
    "    for img in image_names:\n",
    "        image = Image.open(os.path.join(image_path, img))\n",
    "\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        images.append(image)\n",
    "    \n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    model.to(device)\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    \n",
    "    pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "\n",
    "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "\n",
    "    del pixel_values\n",
    "    del output_ids\n",
    "    del model\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "bVWlW5W3MSSI"
   },
   "outputs": [],
   "source": [
    "description_path = \"Descriptions\"\n",
    "if not os.path.exists(description_path):\n",
    "    os.makedirs(description_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSV_ijSHRt_q",
    "outputId": "7e6b934e-81de-4f51-8ced-bf591f8e71fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[0:10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a318ecb95343628d520a531823b6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()lve/main/config.json:   0%|          | 0.00/4.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Insaf\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968a1b1a59044bd1b0d11844a223a7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/982M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b27abbb9ef4021b2e7f74d81584641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()rocessor_config.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insaf\\anaconda3\\envs\\competition01\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:31: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e3b51234e449c886806ffc11a8d7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()okenizer_config.json:   0%|          | 0.00/241 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82727cc8688245dea92d5d02ec99a527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c469db59618c47e3a41b81be1d5c338f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5200328dff4fe09734d3f804ec6fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3421d8cd9114a13b376a8f4012fe330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()cial_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[10:20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[20:30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[30:40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[40:50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[50:60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[60:70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[70:80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[80:90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[90:100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[100:110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[110:120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[120:130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[130:140]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[140:150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[150:160]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[160:170]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[170:180]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[180:190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[190:200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[200:210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[210:220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[220:230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[230:240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[240:250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[250:260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[260:270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[270:280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[280:290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[290:300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[300:310]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[310:320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[320:330]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[330:340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[340:350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[350:360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[360:370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[370:380]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[380:390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[390:400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[400:410]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[410:420]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[420:430]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[430:440]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[440:450]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[450:460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[460:470]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[470:480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[480:490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[490:500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[500:510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[510:520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[520:530]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[530:540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[540:550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[550:560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[560:570]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[570:580]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[580:590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[590:600]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[600:610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[610:620]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[620:630]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[630:640]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[640:650]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[650:660]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[660:670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[670:680]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[680:690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[690:700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[700:710]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[710:720]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[720:730]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[730:740]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[740:750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[750:760]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[760:770]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[770:780]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[780:790]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[790:800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[800:810]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[810:820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[820:830]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[830:840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[840:850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[850:860]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[860:870]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[870:880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[880:890]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[890:900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[900:910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[910:920]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[920:930]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[930:940]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[940:950]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[950:960]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[960:970]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[970:980]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[980:990]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[990:1000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1000:1010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1010:1020]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1020:1030]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1030:1040]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1040:1050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1050:1060]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1060:1070]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1070:1080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1080:1090]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1090:1100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1100:1110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1110:1120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1120:1130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1130:1140]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1140:1150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1150:1160]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1160:1170]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1170:1180]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1180:1190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1190:1200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1200:1210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1210:1220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1220:1230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1230:1240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1240:1250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1250:1260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1260:1270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1270:1280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1280:1290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1290:1300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1300:1310]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1310:1320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1320:1330]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1330:1340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1340:1350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1350:1360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1360:1370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1370:1380]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1380:1390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1390:1400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1400:1410]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1410:1420]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1420:1430]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1430:1440]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1440:1450]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1450:1460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1460:1470]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1470:1480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1480:1490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1490:1500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1500:1510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1510:1520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1520:1530]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1530:1540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1540:1550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1550:1560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1560:1570]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1570:1580]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1580:1590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1590:1600]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1600:1610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1610:1620]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1620:1630]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1630:1640]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1640:1650]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1650:1660]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1660:1670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1670:1680]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1680:1690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1690:1700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1700:1710]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1710:1720]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1720:1730]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1730:1740]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1740:1750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1750:1760]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1760:1770]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1770:1780]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1780:1790]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1790:1800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1800:1810]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1810:1820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1820:1830]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1830:1840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1840:1850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1850:1860]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1860:1870]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1870:1880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1880:1890]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1890:1900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1900:1910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1910:1920]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1920:1930]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1930:1940]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1940:1950]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1950:1960]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1960:1970]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1970:1980]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1980:1990]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[1990:2000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2000:2010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2010:2020]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2020:2030]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2030:2040]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2040:2050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2050:2060]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2060:2070]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2070:2080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2080:2090]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2090:2100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2100:2110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2110:2120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2120:2130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2130:2140]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2140:2150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2150:2160]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2160:2170]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2170:2180]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2180:2190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2190:2200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2200:2210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2210:2220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2220:2230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2230:2240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2240:2250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2250:2260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2260:2270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2270:2280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2280:2290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2290:2300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2300:2310]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2310:2320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2320:2330]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2330:2340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2340:2350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2350:2360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2360:2370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2370:2380]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2380:2390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2390:2400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2400:2410]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2410:2420]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2420:2430]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2430:2440]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2440:2450]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2450:2460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2460:2470]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2470:2480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2480:2490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2490:2500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2500:2510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2510:2520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2520:2530]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2530:2540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2540:2550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2550:2560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2560:2570]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2570:2580]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2580:2590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2590:2600]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2600:2610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2610:2620]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2620:2630]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2630:2640]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2640:2650]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2650:2660]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2660:2670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2670:2680]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2680:2690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2690:2700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2700:2710]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2710:2720]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2720:2730]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2730:2740]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2740:2750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2750:2760]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2760:2770]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2770:2780]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2780:2790]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2790:2800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2800:2810]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2810:2820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2820:2830]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2830:2840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2840:2850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2850:2860]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2860:2870]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2870:2880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2880:2890]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2890:2900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2900:2910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2910:2920]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2920:2930]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2930:2940]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2940:2950]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2950:2960]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2960:2970]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2970:2980]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2980:2990]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[2990:3000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3000:3010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3010:3020]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3020:3030]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3030:3040]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3040:3050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3050:3060]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3060:3070]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3070:3080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3080:3090]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3090:3100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3100:3110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3110:3120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3120:3130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3130:3140]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3140:3150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3150:3160]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3160:3170]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3170:3180]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3180:3190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3190:3200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3200:3210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3210:3220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3220:3230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3230:3240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3240:3250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3250:3260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3260:3270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3270:3280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3280:3290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3290:3300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3300:3310]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3310:3320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3320:3330]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3330:3340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3340:3350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3350:3360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3360:3370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3370:3380]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3380:3390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3390:3400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3400:3410]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3410:3420]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3420:3430]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3430:3440]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3440:3450]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3450:3460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3460:3470]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3470:3480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3480:3490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3490:3500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3500:3510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3510:3520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3520:3530]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3530:3540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3540:3550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3550:3560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3560:3570]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3570:3580]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3580:3590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3590:3600]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3600:3610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3610:3620]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3620:3630]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3630:3640]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3640:3650]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3650:3660]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3660:3670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3670:3680]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3680:3690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3690:3700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3700:3710]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3710:3720]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3720:3730]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3730:3740]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3740:3750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3750:3760]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3760:3770]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3770:3780]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3780:3790]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3790:3800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3800:3810]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3810:3820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3820:3830]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3830:3840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3840:3850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3850:3860]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3860:3870]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3870:3880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3880:3890]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3890:3900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3900:3910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3910:3920]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3920:3930]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3930:3940]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3940:3950]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3950:3960]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3960:3970]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3970:3980]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3980:3990]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[3990:4000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4000:4010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4010:4020]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4020:4030]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4030:4040]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4040:4050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4050:4060]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4060:4070]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4070:4080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data[4080:4090]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.11.crossattention.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "start = 0\n",
    "end = 10\n",
    "descriptions = list()\n",
    "\n",
    "for i in range(round(len(img_list)/batch_size)):\n",
    "    print(f\"Working on Data[{start}:{end}]\")\n",
    "    image_names = img_list[start:end]\n",
    "    desc = get_images_description(folder_images, image_names)\n",
    "    descriptions.extend(desc)\n",
    "    start += 10\n",
    "    end += 10\n",
    "df = pd.DataFrame({\"image\": img_list, \"description\": descriptions})\n",
    "df.to_csv(os.path.join(description_path,\"description.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(description_path,\"description.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cosine Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "JAifYuxWO68q"
   },
   "outputs": [],
   "source": [
    "result_path = \"Results\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "vjaVNM5CNf5R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image.5848.jpg</td>\n",
       "      <td>a number of small birds in a field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image.6307.jpg</td>\n",
       "      <td>a small group of flowers in a flower pot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image.5680.jpg</td>\n",
       "      <td>a vase filled with flowers on top of a table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image.4827.jpg</td>\n",
       "      <td>a statue of a man with a knife in his mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image.4469.jpg</td>\n",
       "      <td>a small white bird standing on top of a white ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image                                        description\n",
       "0  image.5848.jpg                 a number of small birds in a field\n",
       "1  image.6307.jpg           a small group of flowers in a flower pot\n",
       "2  image.5680.jpg       a vase filled with flowers on top of a table\n",
       "3  image.4827.jpg        a statue of a man with a knife in his mouth\n",
       "4  image.4469.jpg  a small white bird standing on top of a white ..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = pd.read_csv(description_path+\"description.csv\")\n",
    "descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buakoPX7NmTB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH+f\"data_split_for_{NAME}.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>goal</td>\n",
       "      <td>football goal</td>\n",
       "      <td>image.4418.jpg</td>\n",
       "      <td>image.4416.jpg</td>\n",
       "      <td>image.4417.jpg</td>\n",
       "      <td>image.4413.jpg</td>\n",
       "      <td>image.4412.jpg</td>\n",
       "      <td>image.4415.jpg</td>\n",
       "      <td>image.4419.jpg</td>\n",
       "      <td>image.4414.jpg</td>\n",
       "      <td>image.2166.jpg</td>\n",
       "      <td>image.1150.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mustard</td>\n",
       "      <td>mustard seed</td>\n",
       "      <td>image.4429.png</td>\n",
       "      <td>image.4422.jpg</td>\n",
       "      <td>image.4423.jpg</td>\n",
       "      <td>image.4424.jpg</td>\n",
       "      <td>image.4421.jpg</td>\n",
       "      <td>image.4427.jpg</td>\n",
       "      <td>image.4426.jpg</td>\n",
       "      <td>image.4420.jpg</td>\n",
       "      <td>image.4425.jpg</td>\n",
       "      <td>image.4428.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seat</td>\n",
       "      <td>eating seat</td>\n",
       "      <td>image.4435.jpg</td>\n",
       "      <td>image.4436.jpg</td>\n",
       "      <td>image.1166.jpg</td>\n",
       "      <td>image.4430.jpg</td>\n",
       "      <td>image.4433.jpg</td>\n",
       "      <td>image.4432.jpg</td>\n",
       "      <td>image.4438.jpg</td>\n",
       "      <td>image.4434.jpg</td>\n",
       "      <td>image.4431.jpg</td>\n",
       "      <td>image.4437.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>navigate</td>\n",
       "      <td>navigate the web</td>\n",
       "      <td>image.4439.jpg</td>\n",
       "      <td>image.4440.jpg</td>\n",
       "      <td>image.4441.jpg</td>\n",
       "      <td>image.4442.jpg</td>\n",
       "      <td>image.4444.jpg</td>\n",
       "      <td>image.4445.jpg</td>\n",
       "      <td>image.1435.jpg</td>\n",
       "      <td>image.4446.png</td>\n",
       "      <td>image.1434.jpg</td>\n",
       "      <td>image.4443.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>butterball</td>\n",
       "      <td>butterball person</td>\n",
       "      <td>image.4454.jpg</td>\n",
       "      <td>image.4450.jpg</td>\n",
       "      <td>image.4455.jpg</td>\n",
       "      <td>image.4453.jpg</td>\n",
       "      <td>image.4448.jpg</td>\n",
       "      <td>image.1253.jpg</td>\n",
       "      <td>image.4451.jpg</td>\n",
       "      <td>image.4452.jpg</td>\n",
       "      <td>image.4447.jpg</td>\n",
       "      <td>image.4449.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                  1               2               3   \\\n",
       "0        goal      football goal  image.4418.jpg  image.4416.jpg   \n",
       "1     mustard       mustard seed  image.4429.png  image.4422.jpg   \n",
       "2        seat        eating seat  image.4435.jpg  image.4436.jpg   \n",
       "3    navigate   navigate the web  image.4439.jpg  image.4440.jpg   \n",
       "4  butterball  butterball person  image.4454.jpg  image.4450.jpg   \n",
       "\n",
       "               4               5               6               7   \\\n",
       "0  image.4417.jpg  image.4413.jpg  image.4412.jpg  image.4415.jpg   \n",
       "1  image.4423.jpg  image.4424.jpg  image.4421.jpg  image.4427.jpg   \n",
       "2  image.1166.jpg  image.4430.jpg  image.4433.jpg  image.4432.jpg   \n",
       "3  image.4441.jpg  image.4442.jpg  image.4444.jpg  image.4445.jpg   \n",
       "4  image.4455.jpg  image.4453.jpg  image.4448.jpg  image.1253.jpg   \n",
       "\n",
       "               8               9               10              11  \n",
       "0  image.4419.jpg  image.4414.jpg  image.2166.jpg  image.1150.jpg  \n",
       "1  image.4426.jpg  image.4420.jpg  image.4425.jpg  image.4428.jpg  \n",
       "2  image.4438.jpg  image.4434.jpg  image.4431.jpg  image.4437.jpg  \n",
       "3  image.1435.jpg  image.4446.png  image.1434.jpg  image.4443.jpg  \n",
       "4  image.4451.jpg  image.4452.jpg  image.4447.jpg  image.4449.jpg  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"Index\"] =  range(data.shape[0]) \n",
    "data2[\"keyword\"] = data[0]\n",
    "data2[\"context\"] = data[1]\n",
    "data2[\"img_1\"] = data[2]\n",
    "data2[\"img_2\"] = data[3]\n",
    "data2[\"img_3\"] = data[4]\n",
    "data2[\"img_4\"] = data[5]\n",
    "data2[\"img_5\"] = data[6]\n",
    "data2[\"img_6\"] = data[7]\n",
    "data2[\"img_7\"] = data[8]\n",
    "data2[\"img_8\"] = data[9]\n",
    "data2[\"img_9\"] = data[10]\n",
    "data2[\"img_10\"] = data[11]\n",
    "data2[\"gold_key\"] = df_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>keyword</th>\n",
       "      <th>context</th>\n",
       "      <th>img_1</th>\n",
       "      <th>img_2</th>\n",
       "      <th>img_3</th>\n",
       "      <th>img_4</th>\n",
       "      <th>img_5</th>\n",
       "      <th>img_6</th>\n",
       "      <th>img_7</th>\n",
       "      <th>img_8</th>\n",
       "      <th>img_9</th>\n",
       "      <th>img_10</th>\n",
       "      <th>gold_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>goal</td>\n",
       "      <td>football goal</td>\n",
       "      <td>image.4418.jpg</td>\n",
       "      <td>image.4416.jpg</td>\n",
       "      <td>image.4417.jpg</td>\n",
       "      <td>image.4413.jpg</td>\n",
       "      <td>image.4412.jpg</td>\n",
       "      <td>image.4415.jpg</td>\n",
       "      <td>image.4419.jpg</td>\n",
       "      <td>image.4414.jpg</td>\n",
       "      <td>image.2166.jpg</td>\n",
       "      <td>image.1150.jpg</td>\n",
       "      <td>image.2166.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mustard</td>\n",
       "      <td>mustard seed</td>\n",
       "      <td>image.4429.png</td>\n",
       "      <td>image.4422.jpg</td>\n",
       "      <td>image.4423.jpg</td>\n",
       "      <td>image.4424.jpg</td>\n",
       "      <td>image.4421.jpg</td>\n",
       "      <td>image.4427.jpg</td>\n",
       "      <td>image.4426.jpg</td>\n",
       "      <td>image.4420.jpg</td>\n",
       "      <td>image.4425.jpg</td>\n",
       "      <td>image.4428.jpg</td>\n",
       "      <td>image.4429.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>seat</td>\n",
       "      <td>eating seat</td>\n",
       "      <td>image.4435.jpg</td>\n",
       "      <td>image.4436.jpg</td>\n",
       "      <td>image.1166.jpg</td>\n",
       "      <td>image.4430.jpg</td>\n",
       "      <td>image.4433.jpg</td>\n",
       "      <td>image.4432.jpg</td>\n",
       "      <td>image.4438.jpg</td>\n",
       "      <td>image.4434.jpg</td>\n",
       "      <td>image.4431.jpg</td>\n",
       "      <td>image.4437.jpg</td>\n",
       "      <td>image.4432.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>navigate</td>\n",
       "      <td>navigate the web</td>\n",
       "      <td>image.4439.jpg</td>\n",
       "      <td>image.4440.jpg</td>\n",
       "      <td>image.4441.jpg</td>\n",
       "      <td>image.4442.jpg</td>\n",
       "      <td>image.4444.jpg</td>\n",
       "      <td>image.4445.jpg</td>\n",
       "      <td>image.1435.jpg</td>\n",
       "      <td>image.4446.png</td>\n",
       "      <td>image.1434.jpg</td>\n",
       "      <td>image.4443.jpg</td>\n",
       "      <td>image.1435.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>butterball</td>\n",
       "      <td>butterball person</td>\n",
       "      <td>image.4454.jpg</td>\n",
       "      <td>image.4450.jpg</td>\n",
       "      <td>image.4455.jpg</td>\n",
       "      <td>image.4453.jpg</td>\n",
       "      <td>image.4448.jpg</td>\n",
       "      <td>image.1253.jpg</td>\n",
       "      <td>image.4451.jpg</td>\n",
       "      <td>image.4452.jpg</td>\n",
       "      <td>image.4447.jpg</td>\n",
       "      <td>image.4449.jpg</td>\n",
       "      <td>image.4455.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index     keyword            context           img_1           img_2  \\\n",
       "0      0        goal      football goal  image.4418.jpg  image.4416.jpg   \n",
       "1      1     mustard       mustard seed  image.4429.png  image.4422.jpg   \n",
       "2      2        seat        eating seat  image.4435.jpg  image.4436.jpg   \n",
       "3      3    navigate   navigate the web  image.4439.jpg  image.4440.jpg   \n",
       "4      4  butterball  butterball person  image.4454.jpg  image.4450.jpg   \n",
       "\n",
       "            img_3           img_4           img_5           img_6  \\\n",
       "0  image.4417.jpg  image.4413.jpg  image.4412.jpg  image.4415.jpg   \n",
       "1  image.4423.jpg  image.4424.jpg  image.4421.jpg  image.4427.jpg   \n",
       "2  image.1166.jpg  image.4430.jpg  image.4433.jpg  image.4432.jpg   \n",
       "3  image.4441.jpg  image.4442.jpg  image.4444.jpg  image.4445.jpg   \n",
       "4  image.4455.jpg  image.4453.jpg  image.4448.jpg  image.1253.jpg   \n",
       "\n",
       "            img_7           img_8           img_9          img_10  \\\n",
       "0  image.4419.jpg  image.4414.jpg  image.2166.jpg  image.1150.jpg   \n",
       "1  image.4426.jpg  image.4420.jpg  image.4425.jpg  image.4428.jpg   \n",
       "2  image.4438.jpg  image.4434.jpg  image.4431.jpg  image.4437.jpg   \n",
       "3  image.1435.jpg  image.4446.png  image.1434.jpg  image.4443.jpg   \n",
       "4  image.4451.jpg  image.4452.jpg  image.4447.jpg  image.4449.jpg   \n",
       "\n",
       "         gold_key  \n",
       "0  image.2166.jpg  \n",
       "1  image.4429.png  \n",
       "2  image.4432.jpg  \n",
       "3  image.1435.jpg  \n",
       "4  image.4455.jpg  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "QGtjGX1mPIJJ"
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['img_1', 'img_2', 'img_3', 'img_4', 'img_5', 'img_6', 'img_7', 'img_8', 'img_9', 'img_10', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "yDcQnr6TNs79"
   },
   "outputs": [],
   "source": [
    "sentence_model =  SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data2.iterrows():\n",
    "    embeddings_1 = sentence_model.encode(row['context'], convert_to_tensor=True)\n",
    "    scores = list()\n",
    "    for i in range(1, 11):\n",
    "        desc = descriptions[descriptions['image'] == row[f'img_{i}']]['description'].values[0]\n",
    "        embeddings_2 = sentence_model.encode(desc, convert_to_tensor=True)\n",
    "        cosine_scores = util.pytorch_cos_sim(embeddings_1, embeddings_2).item()\n",
    "        \n",
    "        scores.append(cosine_scores)\n",
    "        result.loc[idx, f'img_{i}'] = cosine_scores\n",
    "\n",
    "        del embeddings_2\n",
    "    result.loc[idx, 'label'] = row[f\"img_{np.argmax(scores) + 1}\"]\n",
    "    del embeddings_1\n",
    "result.to_csv(os.path.join(result_path,\"similarities_and_prediction.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                  462\n",
       "keyword            diamond\n",
       "context      diamond field\n",
       "img_1       image.8090.jpg\n",
       "img_2       image.8091.jpg\n",
       "img_3       image.8092.jpg\n",
       "img_4       image.8093.jpg\n",
       "img_5       image.8098.jpg\n",
       "img_6       image.8097.jpg\n",
       "img_7       image.8094.jpg\n",
       "img_8       image.8099.jpg\n",
       "img_9       image.8095.jpg\n",
       "img_10      image.8096.jpg\n",
       "gold_key    image.8095.jpg\n",
       "Name: 462, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_images = []\n",
    "final_result_distances = []\n",
    "for idx, row in result.iterrows():\n",
    "    dist_test = np.array(result.iloc[idx][:-1])\n",
    "    ranked_dist = -np.sort(-dist_test)\n",
    "    ranked_dist_indices = np.argsort(-dist_test)\n",
    "    sorted_df = np.array(data.iloc[idx][ranked_dist_indices+2])\n",
    "    final_result_images.append(sorted_df)\n",
    "    final_result_distances.append(ranked_dist)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tocsv = pd.DataFrame()\n",
    "result_tocsv[\"language\"]=[]\n",
    "result_tocsv[\"data\"]=[]\n",
    "result_tocsv[\"candidate\"]=final_result_images\n",
    "result_tocsv[\"relevance\"]=final_result_distances\n",
    "result_tocsv[\"language\"]=language\n",
    "result_tocsv[\"gold\"]=df_gold.values\n",
    "result_tocsv[\"data\"]=range(len(final_result_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>data</th>\n",
       "      <th>candidate</th>\n",
       "      <th>relevance</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>0</td>\n",
       "      <td>[image.4415.jpg, image.2166.jpg, image.4418.jp...</td>\n",
       "      <td>[0.421658992767334, 0.3936811685562134, 0.3816...</td>\n",
       "      <td>image.2166.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>[image.4429.png, image.4423.jpg, image.4427.jp...</td>\n",
       "      <td>[0.2836892902851105, 0.27905523777008057, 0.27...</td>\n",
       "      <td>image.4429.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>2</td>\n",
       "      <td>[image.4430.jpg, image.4434.jpg, image.4438.jp...</td>\n",
       "      <td>[0.24093304574489594, 0.20179305970668793, 0.1...</td>\n",
       "      <td>image.4432.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>3</td>\n",
       "      <td>[image.1435.jpg, image.4445.jpg, image.4441.jp...</td>\n",
       "      <td>[0.26168426871299744, 0.11431465297937393, 0.0...</td>\n",
       "      <td>image.1435.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>4</td>\n",
       "      <td>[image.4450.jpg, image.4455.jpg, image.1253.jp...</td>\n",
       "      <td>[0.34032198786735535, 0.24167302250862122, 0.2...</td>\n",
       "      <td>image.4455.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>english</td>\n",
       "      <td>458</td>\n",
       "      <td>[image.8066.jpg, image.1604.jpg, image.8064.jp...</td>\n",
       "      <td>[0.3713851571083069, 0.16832831501960754, 0.15...</td>\n",
       "      <td>image.8063.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>english</td>\n",
       "      <td>459</td>\n",
       "      <td>[image.8072.jpg, image.8071.jpg, image.8076.jp...</td>\n",
       "      <td>[0.4677559435367584, 0.3392558693885803, 0.337...</td>\n",
       "      <td>image.8069.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>english</td>\n",
       "      <td>460</td>\n",
       "      <td>[image.8081.jpg, image.4995.jpg, image.8080.jp...</td>\n",
       "      <td>[0.473016619682312, 0.08488843590021133, 0.066...</td>\n",
       "      <td>image.8081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>english</td>\n",
       "      <td>461</td>\n",
       "      <td>[image.8089.jpg, image.7279.jpg, image.192.jpg...</td>\n",
       "      <td>[0.21371154487133026, 0.20012266933918, 0.1846...</td>\n",
       "      <td>image.8089.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>english</td>\n",
       "      <td>462</td>\n",
       "      <td>[image.8097.jpg, image.8092.jpg, image.8095.jp...</td>\n",
       "      <td>[0.465354323387146, 0.40822577476501465, 0.388...</td>\n",
       "      <td>image.8095.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    language  data                                          candidate  \\\n",
       "0    english     0  [image.4415.jpg, image.2166.jpg, image.4418.jp...   \n",
       "1    english     1  [image.4429.png, image.4423.jpg, image.4427.jp...   \n",
       "2    english     2  [image.4430.jpg, image.4434.jpg, image.4438.jp...   \n",
       "3    english     3  [image.1435.jpg, image.4445.jpg, image.4441.jp...   \n",
       "4    english     4  [image.4450.jpg, image.4455.jpg, image.1253.jp...   \n",
       "..       ...   ...                                                ...   \n",
       "458  english   458  [image.8066.jpg, image.1604.jpg, image.8064.jp...   \n",
       "459  english   459  [image.8072.jpg, image.8071.jpg, image.8076.jp...   \n",
       "460  english   460  [image.8081.jpg, image.4995.jpg, image.8080.jp...   \n",
       "461  english   461  [image.8089.jpg, image.7279.jpg, image.192.jpg...   \n",
       "462  english   462  [image.8097.jpg, image.8092.jpg, image.8095.jp...   \n",
       "\n",
       "                                             relevance            gold  \n",
       "0    [0.421658992767334, 0.3936811685562134, 0.3816...  image.2166.jpg  \n",
       "1    [0.2836892902851105, 0.27905523777008057, 0.27...  image.4429.png  \n",
       "2    [0.24093304574489594, 0.20179305970668793, 0.1...  image.4432.jpg  \n",
       "3    [0.26168426871299744, 0.11431465297937393, 0.0...  image.1435.jpg  \n",
       "4    [0.34032198786735535, 0.24167302250862122, 0.2...  image.4455.jpg  \n",
       "..                                                 ...             ...  \n",
       "458  [0.3713851571083069, 0.16832831501960754, 0.15...  image.8063.jpg  \n",
       "459  [0.4677559435367584, 0.3392558693885803, 0.337...  image.8069.jpg  \n",
       "460  [0.473016619682312, 0.08488843590021133, 0.066...  image.8081.jpg  \n",
       "461  [0.21371154487133026, 0.20012266933918, 0.1846...  image.8089.jpg  \n",
       "462  [0.465354323387146, 0.40822577476501465, 0.388...  image.8095.jpg  \n",
       "\n",
       "[463 rows x 5 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tocsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the csv of results\n",
    "       \n",
    "result_name =os.path.join(result_path, \"test_sorting2.csv\" )\n",
    "result_tocsv.to_csv(result_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "fo8EORVUNw_X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3045356371490281"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(data2['gold_key'], result['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "861422ce924561d14451c158b4f671c78a8ad5148ef4e5f0393ebe2641d92b66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
